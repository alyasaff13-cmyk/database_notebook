{"cells":[{"cell_type":"markdown","metadata":{"id":"udk8HMvTGTcw"},"source":["#**Машинное обучение ИБ-2024**\n","\n","#**Домашнее задание 2.**\n","#Классификация, KNN, LogReg, SVC."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"3SlSvjUyIx6P","executionInfo":{"status":"ok","timestamp":1730410757925,"user_tz":-180,"elapsed":8446,"user":{"displayName":"Даниил Бураков","userId":"09897088617103092800"}}},"outputs":[],"source":["from typing import Tuple, List\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","%matplotlib inline\n","\n","sns.set(style=\"darkgrid\")"]},{"cell_type":"markdown","metadata":{"id":"anNYyOmryCU-"},"source":["## **Теоретическая Часть**"]},{"cell_type":"markdown","metadata":{"id":"gOsiAL0yHPZc"},"source":["Мы рассматриваем задачу бинарной классификации. Для прогнозирования мы хотели бы использовать модель логистической регрессии. Для регуляризации мы добавляем комбинацию штрафов в размере $l_2$ и $l_1$ (Elastic Net).\n","\n","Каждый объект в обучающем наборе данных индексируется с помощью $i$ и описывается парой: объекты $x_i\\in\\mathbb{R}^{K}$ и двоичные метки $y_i$. Модель параметризуется со смещением $w_0\\in\\mathbb{R}$ и весами $w\\in\\mathbb{R}^K$.\n","\n","Задача оптимизации в отношении $w_0, w$ заключается в следующем (Elastic Net Loss):\n","\n","$$L(w, w_0) = \\frac{1}{N} \\sum_{i=1}^N \\ln(1+\\exp(-y_i(w^\\top x_i+w_0))) + \\gamma \\|w\\|_1 + \\beta \\|w\\|_2^2$$.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VDvxlzjaHtBv"},"source":["Градиенты функции потерь логистической регрессии представлены ниже:"]},{"cell_type":"markdown","metadata":{"id":"PeDXXb9kHqiE"},"source":["$$dL(w, w_0)/ dw = -\\frac{1}{N}  \\frac{X*y^\\top}{1 + \\exp(y (Xw+w_0)))} + \\gamma * sign(w) + 2 * beta * w$$\n","\n","$$dL(w, w_0)/ dw_0 = -\\frac{1}{N}  \\frac{y}{1 + \\exp(y*(Xw+w_0)))}$$"]},{"cell_type":"markdown","metadata":{"id":"StAKNPmaIj5C"},"source":["#### 1. [0.5 Балл] Реализуйте функцию, выдающий значение функции потерь логичтической регрессии:"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"_z1jsC30GSii","executionInfo":{"status":"ok","timestamp":1730410785455,"user_tz":-180,"elapsed":406,"user":{"displayName":"Даниил Бураков","userId":"09897088617103092800"}}},"outputs":[],"source":["def loss(X, y, w: List[float], w0: float, gamma=1., beta=1.) -> float:\n","    N = len(y)\n","    w = np.array(w)\n","    linear_comb = X.dot(w) + w0\n","    log_loss = np.log(1 + np.exp(-y * linear_comb))\n","    avg_log_loss = np.mean(log_loss)\n","    regularization = (gamma / 2) * np.sum(w ** 2) + (beta / 2) * w0 ** 2\n","\n","    total_loss = avg_log_loss + regularization\n","    return total_loss"]},{"cell_type":"markdown","metadata":{"id":"WIlZHGAuIqEP"},"source":["#### 2. [0.5 Балл] Реализуйте функцию, которая будет возвращать градиенты весов вашей модели Логистической регрессии:"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"p7Pg4o4_IpFs","executionInfo":{"status":"ok","timestamp":1730410787627,"user_tz":-180,"elapsed":405,"user":{"displayName":"Даниил Бураков","userId":"09897088617103092800"}}},"outputs":[],"source":["def get_grad(X: np.ndarray, y: np.ndarray, w: List[float], w0: float, gamma=1.0, beta=1.0) -> Tuple[List[float], float]:\n","    N = len(y)\n","    w = np.array(w)\n","\n","    linear_comb = X.dot(w) + w0\n","    sigmoid = 1 / (1 + np.exp(-y * linear_comb))\n","\n","    grad_w = -np.mean((1 - sigmoid) * y[:, np.newaxis] * X, axis=0) + gamma * w\n","    grad_w0 = -np.mean((1 - sigmoid) * y) + beta * w0\n","\n","    return grad_w.tolist(), grad_w0"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Q9SndxzbI8yy","colab":{"base_uri":"https://localhost:8080/","height":332},"executionInfo":{"status":"error","timestamp":1730410788372,"user_tz":-180,"elapsed":5,"user":{"displayName":"Даниил Бураков","userId":"09897088617103092800"}},"outputId":"86c45171-72d8-44a0-e2b0-a60210796a1b"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"operands could not be broadcast together with shapes (10,10) (10,5) ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-cf55d646ab98>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgrad_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_w0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m assert(np.allclose(grad_w,\n\u001b[1;32m     10\u001b[0m                    \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2.73262076\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.87176281\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.30051144\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.53598941\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2.71198109\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-d0d97becde96>\u001b[0m in \u001b[0;36mget_grad\u001b[0;34m(X, y, w, w0, gamma, beta)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msigmoid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlinear_comb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mgrad_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mgrad_w0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,10) (10,5) "]}],"source":["# код для проверки\n","\n","np.random.seed(42)\n","X = np.random.multivariate_normal(np.arange(5), np.eye(5), size=10)\n","y = np.random.binomial(1, 0.42, size=10)\n","w, w0 = np.random.normal(size=5), np.random.normal()\n","\n","grad_w, grad_w0 = get_grad(X, y, w, w0)\n","assert(np.allclose(grad_w,\n","                   [-2.73262076, -1.87176281, 1.30051144, 2.53598941, -2.71198109],\n","                   rtol=1e-2) & \\\n","       np.allclose(grad_w0,\n","                   -0.2078231418067844,\n","                   rtol=1e-2)\n",")"]},{"cell_type":"markdown","metadata":{"id":"3gINHTOgJaS7"},"source":["####  3. [1 Балл]  Реализуйте класс для модели логистической регрессии, используя выше написанные функции:"]},{"cell_type":"markdown","metadata":{"id":"Xo-IJWGTDUQH"},"source":["Модель должна обучаться методом SGD."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"FfwNPBafJSVT","executionInfo":{"status":"ok","timestamp":1730410846787,"user_tz":-180,"elapsed":646,"user":{"displayName":"Даниил Бураков","userId":"09897088617103092800"}}},"outputs":[],"source":["from sklearn.base import BaseEstimator, ClassifierMixin\n","from sklearn.metrics import roc_curve"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"43z5BoIRJjV9","executionInfo":{"status":"ok","timestamp":1730410847633,"user_tz":-180,"elapsed":410,"user":{"displayName":"Даниил Бураков","userId":"09897088617103092800"}}},"outputs":[],"source":["class Logit(BaseEstimator, ClassifierMixin):\n","    def __init__(self, beta=1.0, gamma=1.0, lr=1e-2, tolerance=1e-8, max_iter=1000, random_state=42):\n","        self.beta = beta\n","        self.gamma = gamma\n","        self.lr = lr\n","        self.tolerance = tolerance\n","        self.max_iter = max_iter\n","        self.random_state = random_state\n","        self.w = None\n","        self.w0 = None\n","\n","    def fit(self, X: np.ndarray, y: np.ndarray):\n","        np.random.seed(self.random_state)\n","        y = 2 * y - 1\n","\n","        n_features = X.shape[1]\n","        self.w = np.random.normal(size=n_features)\n","        self.w0 = np.random.normal()\n","\n","        for i in range(self.max_iter):\n","            grad_w, grad_w0 = self.get_grad(X, y, self.w, self.w0, gamma=self.gamma, beta=self.beta)\n","\n","            self.w -= self.lr * np.array(grad_w)\n","            self.w0 -= self.lr * grad_w0\n","\n","            if np.linalg.norm(grad_w) < self.tolerance and abs(grad_w0) < self.tolerance:\n","                break\n","\n","    def predict(self, X: np.ndarray) -> np.ndarray:\n","        probs = self.predict_proba(X)\n","        return (probs >= 0.5).astype(int)\n","\n","    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n","        linear_comb = X.dot(self.w) + self.w0\n","        return 1 / (1 + np.exp(-linear_comb))\n","\n","    def get_grad(self, X: np.ndarray, y: np.ndarray, w: List[float], w0: float, gamma=1.0, beta=1.0) -> Tuple[List[float], float]:\n","        N = len(y)\n","        linear_comb = X.dot(w) + w0\n","        sigmoid = 1 / (1 + np.exp(-y * linear_comb))\n","\n","        grad_w = -np.mean((1 - sigmoid) * y[:, np.newaxis] * X, axis=0) + gamma * np.array(w)\n","        grad_w0 = -np.mean((1 - sigmoid) * y) + beta * w0\n","\n","        return grad_w.tolist(), grad_w0\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Y0dzDEMFJmR3","colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"status":"error","timestamp":1730410854516,"user_tz":-180,"elapsed":377,"user":{"displayName":"Даниил Бураков","userId":"09897088617103092800"}},"outputId":"e6952fdc-1b8e-463d-8ea7-be72570ef87d"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"operands could not be broadcast together with shapes (1800,1800) (1800,2) ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-9ced5be0400c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                                random_state=42, n_clusters_per_class=1)\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-40cfca74aaee>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mgrad_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_w0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-40cfca74aaee>\u001b[0m in \u001b[0;36mget_grad\u001b[0;34m(self, X, y, w, w0, gamma, beta)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0msigmoid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlinear_comb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mgrad_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mgrad_w0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1800,1800) (1800,2) "]}],"source":["# этот код менять не надо!\n","from sklearn.datasets import make_classification\n","X, y = make_classification(n_samples=1800, n_features=2, n_redundant=0, n_informative=2,\n","                               random_state=42, n_clusters_per_class=1)\n","model = Logit(beta=1.0, gamma=1.0, lr=1e-2, tolerance=1e-8, max_iter=1000)\n","model.fit(X, y)\n","\n","y_pred = model.predict(X)\n","y_proba = model.predict_proba(X)\n","\n","print(\"Predicted Labels:\", y_pred)\n","print(\"Predicted Probabilities:\", y_proba[:5])"]},{"cell_type":"markdown","metadata":{"id":"fedP3pyAs9Xk"},"source":["####  4. [0.5 Балл]  Реализуйте функцию, которая отрисовывает объекты вашего датасета, их метки и разделяющую гиперплоскость, полученную от Логистической регрессии (пример того, что должно получиться ниже):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LVMUvlkpJpvu"},"outputs":[],"source":["def plot_decision_boundary(model, X, y):\n","    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n","    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n","    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n","\n","    grid = np.c_[xx.ravel(), yy.ravel()]\n","    probs = model.predict_proba(grid).reshape(xx.shape)\n","\n","    plt.contourf(xx, yy, probs, levels=[0, 0.5, 1], colors=['#FFAAAA', '#AAAAFF'], alpha=0.3)\n","\n","    plt.scatter(X[y == -1][:, 0], X[y == -1][:, 1], color='red', label='Class -1', edgecolor='k')\n","    plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], color='blue', label='Class 1', edgecolor='k')\n","\n","    plt.xlabel('Feature 1')\n","    plt.ylabel('Feature 2')\n","    plt.legend()\n","    plt.title('Decision Boundary for Logistic Regression')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PISzKE_xJsZh"},"outputs":[],"source":["model = Logit(0,0)\n","y[y == 0] = -1\n","model.fit(X, y)\n","plot_decision_boundary(model, X, y)"]},{"cell_type":"markdown","metadata":{"id":"4lyS4dNXPYr1"},"source":["#### 5. [0.5 Балл] Для предыдущей задачи отобразите на графике, как изменяется значение функция потерь от номера итерации."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aTj-XMOvZ2YG"},"outputs":[],"source":["def plot_loss_history(model):\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(model.loss_history, label=\"Loss over iterations\")\n","    plt.xlabel(\"Iteration\")\n","    plt.ylabel(\"Loss\")\n","    plt.title(\"Loss vs. Iterations\")\n","    plt.legend()\n","    plt.grid()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SJeDlYsJt8W0"},"outputs":[],"source":["plot_loss_history(model)"]},{"cell_type":"markdown","metadata":{"id":"3zHxhSSnt7Iw"},"source":["#### 6. [2 Балл] Для данных, на которых тестировали модель Логистической регрессии, заиспользуйте модель SVC из библиотеки sklearn. Попробуйте различные ядра (kernel) и различные коэфициенты C. Посмотрите на метрики, которые мы обсуждали на занятии (Acc, Precision, Recall, AUC-ROC, F1-Score)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qpwzcThrvCyU"},"outputs":[],"source":["rom sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","from sklearn.model_selection import train_test_split\n","\n","X, y = make_classification(n_samples=1800, n_features=2, n_redundant=0, n_informative=2,\n","                           random_state=42, n_clusters_per_class=1)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eW36FcFAg-Nj"},"outputs":[],"source":["kernels = ['linear', 'rbf', 'poly']\n","C_values = [0.1, 1, 10]\n","\n","results = []\n","for kernel in kernels:\n","    for C in C_values:\n","        model = SVC(kernel=kernel, C=C, probability=True, random_state=42)\n","        model.fit(X_train, y_train)\n","\n","        y_pred = model.predict(X_test)\n","        y_proba = model.predict_proba(X_test)[:, 1]\n","\n","        acc = accuracy_score(y_test, y_pred)\n","        precision = precision_score(y_test, y_pred)\n","        recall = recall_score(y_test, y_pred)\n","        f1 = f1_score(y_test, y_pred)\n","        auc_roc = roc_auc_score(y_test, y_proba)\n","\n","        results.append({\n","            'Kernel': kernel,\n","            'C': C,\n","            'Accuracy': acc,\n","            'Precision': precision,\n","            'Recall': recall,\n","            'F1-Score': f1,\n","            'AUC-ROC': auc_roc\n","        })\n","\n","results_df = pd.DataFrame(results)\n","print(results_df)"]},{"cell_type":"markdown","metadata":{"id":"tAyn5WAYvefO"},"source":["#### 7. [2 Балл] Реализуйте класс KNNClassifier, который должен реализовывать классификацию путем нахождения k ближайших соседей. В методе predict_proba Вам необходимо выдавать вектор вероятностей для каждого объекта, который означает, что объект является экземпляром i-го класса с p_i вероятностью. Протестируйте Ваш класс на данных, сгенерированных выше, посмотрите на метрики (Acc, Precision, Recall, AUC-ROC, F1-Score)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eFNJLQ_Vv4dU"},"outputs":[],"source":["from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","\n","X, y = make_classification(n_samples=1800, n_features=2, n_redundant=0, n_informative=2, random_state=42, n_clusters_per_class=1)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","knn_model = KNNClassifier(k=5)\n","knn_model.fit(X_train, y_train)\n","\n","y_pred = knn_model.predict(X_test)\n","y_proba = knn_model.predict_proba(X_test)[:, 1]  # Вероятности для класса 1\n","\n","acc = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","auc_roc = roc_auc_score(y_test, y_proba)\n","\n","print(f\"Accuracy: {acc}\")\n","print(f\"Precision: {precision}\")\n","print(f\"Recall: {recall}\")\n","print(f\"F1-Score: {f1}\")\n","print(f\"AUC-ROC: {auc_roc}\")\n"]},{"cell_type":"markdown","metadata":{"id":"RPABb_kMysd6"},"source":["## **Практическая часть**"]},{"cell_type":"markdown","metadata":{"id":"q8vRW2QayxIX"},"source":["В этом задании мы будем работать с Датасетом Fashion Mnist. Это датасет, который представляет изображения одного канала с различными типами одежды. Вам необходимо провести полный пайплайн обучения моделей (KNN и Logreg), которые вы можете импортировать из библиотеки sklearn."]},{"cell_type":"markdown","metadata":{"id":"BePXBACs0Z2F"},"source":["#### 8. [0 Балл] Импортируйте датафрейм из csv файла. Поделите выборку следующим образом - :50000 (Train) и 50000: (Test)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Elrow43kywfP"},"outputs":[],"source":["df = pd.read_csv(\"train.csv\", encoding='utf-8')\n","train_df = df.iloc[:50000]\n","test_df = df.iloc[50000:]\n","\n","df"]},{"cell_type":"markdown","metadata":{"id":"_3X27C9W8vyx"},"source":["#### 9. [0.5 Балл] Визуализируйте некоторые из объектов датасета. В колонках отображены яркости пикселей, которые представляют из себя изображения Fashion Mnist. С помощью matplotlib визуализируйте по одному представителю каждого класса."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KanzBBUL9Svb"},"outputs":[],"source":["unique_classes = df['Category'].unique()\n","\n","# Создаем фигуру с подграфиками\n","plt.figure(figsize=(10, 10))\n","\n","# Цикл по каждому классу\n","for i, category in enumerate(unique_classes):\n","    # Выбираем первый экземпляр данного класса\n","    class_sample = df[df['Category'] == category].iloc[0, 2:]  # Яркости пикселей, начиная с третьей колонки\n","\n","    # Преобразуем яркости пикселей в 28x28 матрицу\n","    image = class_sample.values.reshape(28, 28)\n","\n","    # Отображаем изображение на графике\n","    plt.subplot(4, 4, i + 1)  # Создаем сетку 4x4 для графиков\n","    plt.imshow(image, cmap='gray')\n","    plt.title(f'Class {category}')\n","    plt.axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"xfdGxPq19ef0"},"source":["#### 10. [0.5 Балл] Отнормируйте признаки в датасете, попробуйте два варианта StandartScaller и MinMaxScaller."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TOpmPYll-Fu1"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","X = df.iloc[:, 2:]  # Признаки\n","y = df['Category']  # Метки классов\n","\n","# Нормализация с помощью StandardScaler\n","standard_scaler = StandardScaler()\n","X_standard_scaled = standard_scaler.fit_transform(X)\n","\n","# Нормализация с помощью MinMaxScaler\n","minmax_scaler = MinMaxScaler()\n","X_minmax_scaled = minmax_scaler.fit_transform(X)\n","\n","# Преобразование обратно в DataFrame для наглядности (необязательно)\n","X_standard_scaled_df = pd.DataFrame(X_standard_scaled, columns=X.columns)\n","X_minmax_scaled_df = pd.DataFrame(X_minmax_scaled, columns=X.columns)\n","\n","# Проверка\n","print(\"StandardScaler нормализованный датафрейм:\\n\", X_standard_scaled_df.head())\n","print(\"MinMaxScaler нормализованный датафрейм:\\n\", X_minmax_scaled_df.head())"]},{"cell_type":"markdown","metadata":{"id":"0OMKYo3K-IQ2"},"source":["#### 10. [2 Балл] Проведите эксперименты: для моделей KNeighborsClassifier и LogisticRegression подберите гиперпараметры с помощью GridSerchCV (минимум 5 фолдов). Получите качество моделей на тестовой выборке. Основная метрика в данном задании будет accuracy. Сравните эти две модели. Какая модель показывает лучшее качество, предположите почему и напишите ответ.\n","\n","**NB!**: в задании нужно подбирать несколько гиперпараметров по сетке. Какие гиперпараметры подбирать - решаете Вы сами. Обязательно обоснуйте, почему и какие параметры Вы подбираете! Например, подбор только гиперпараметра C в LogisticRegression не будет засчитываться как решение данного задания! Попытайтесь серьезно отнестись к нему, будто вы за это получите зарплату 300к."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9V50Z-d5_GFG"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"MlMatXPK_56f"},"source":["## **Бонусы**"]},{"cell_type":"markdown","metadata":{"id":"eSP3Qx8FAFsA"},"source":["#### Задача 1. [1 Балл] У Вас есть датасет с 10**4 объектами. У всех объектов два признака и все они одинаковые у всех объектов. Однако, 5000 - отрицательного класса и 5000 - положительного класса. Вы запускате Логистическую регрессию для классификации на данном датасете. Что Вы получите в итоге обучения данной модели на SGD? Ответ обоснуйте."]},{"cell_type":"markdown","metadata":{"id":"W4qCiGesA258"},"source":["#### Задача 2. [1 Балл] При классификации Fashion Mnist модель Логистической регрессии на обучении многоклассовой классификации методом One-VS-All у Вас получилось k классификаторов. Изобразите веса ваших полученных моделей как изображения в matplotlib. Возможно, модель выучила какие-то графические паттерны в данных? Ответ обоснуйте."]},{"cell_type":"markdown","metadata":{"id":"fwO_-__KB2Zy"},"source":["#### Задача 3. [1 Балл] В задаче классификации Fashion Mnist Вы попытались выбить какой-то accuracy. Для получения бонусного балла Вам нужно на той же самой выборке получить значение метрики accuracy > 0.87 на тесте (Тестовую выборку менять нельзя, но обучающую можно). Какими моделями и методами Вы это будете делать - на Ваше усмотрение, но **нельзя использовать никакие нейронные сети**. Необходимо получить модель машинного обучения, выполняющую эту задачу."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y5PSUQ7qEJOW"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}