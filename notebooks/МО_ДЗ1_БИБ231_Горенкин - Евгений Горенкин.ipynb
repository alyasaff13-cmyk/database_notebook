{"cells":[{"cell_type":"code","execution_count":null,"id":"ac543654-0944-41ad-9cdc-5d8cb39b2886","metadata":{"id":"ac543654-0944-41ad-9cdc-5d8cb39b2886","outputId":"942c4975-59f7-43d8-f907-102393dac0e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Читаем датасет...\n","Добавляем is_Moscow и is_Saint_Peterburg ...\n","\n","Датасет большеват (11,358,150). Для моего KNN использую первые 100,000 строк.\n","\n","Числовые признаки: 7\n","Категориальные признаки: 4\n","\n","Описание целевой переменной:\n","count    1.000000e+05\n","mean     1.225384e+07\n","std      2.009979e+09\n","min      1.000000e+00\n","25%      2.200000e+06\n","50%      3.400000e+06\n","75%      5.700000e+06\n","max      6.355524e+11\n","Name: price, dtype: float64\n","\n","Обучающая выборка: (80000, 16), Тестовая выборка: (20000, 16)\n","\n","1) Мой KNN on на \"маленькой\" подвыборке\n","Обработано 200/20000 тестовых строк\n","Обработано 400/20000 тестовых строк\n","Обработано 600/20000 тестовых строк\n","Обработано 800/20000 тестовых строк\n","Обработано 1000/20000 тестовых строк\n","Обработано 1200/20000 тестовых строк\n","Обработано 1400/20000 тестовых строк\n","Обработано 1600/20000 тестовых строк\n","Обработано 1800/20000 тестовых строк\n","Обработано 2000/20000 тестовых строк\n","Обработано 2200/20000 тестовых строк\n","Обработано 2400/20000 тестовых строк\n","Обработано 2600/20000 тестовых строк\n","Обработано 2800/20000 тестовых строк\n","Обработано 3000/20000 тестовых строк\n","Обработано 3200/20000 тестовых строк\n","Обработано 3400/20000 тестовых строк\n","Обработано 3600/20000 тестовых строк\n","Обработано 3800/20000 тестовых строк\n","Обработано 4000/20000 тестовых строк\n","Обработано 4200/20000 тестовых строк\n","Обработано 4400/20000 тестовых строк\n","Обработано 4600/20000 тестовых строк\n","Обработано 4800/20000 тестовых строк\n","Обработано 5000/20000 тестовых строк\n","Обработано 5200/20000 тестовых строк\n","Обработано 5400/20000 тестовых строк\n","Обработано 5600/20000 тестовых строк\n","Обработано 5800/20000 тестовых строк\n","Обработано 6000/20000 тестовых строк\n","Обработано 6200/20000 тестовых строк\n","Обработано 6400/20000 тестовых строк\n","Обработано 6600/20000 тестовых строк\n","Обработано 6800/20000 тестовых строк\n","Обработано 7000/20000 тестовых строк\n","Обработано 7200/20000 тестовых строк\n","Обработано 7400/20000 тестовых строк\n","Обработано 7600/20000 тестовых строк\n","Обработано 7800/20000 тестовых строк\n","Обработано 8000/20000 тестовых строк\n","Обработано 8200/20000 тестовых строк\n","Обработано 8400/20000 тестовых строк\n","Обработано 8600/20000 тестовых строк\n","Обработано 8800/20000 тестовых строк\n","Обработано 9000/20000 тестовых строк\n","Обработано 9200/20000 тестовых строк\n","Обработано 9400/20000 тестовых строк\n","Обработано 9600/20000 тестовых строк\n","Обработано 9800/20000 тестовых строк\n","Обработано 10000/20000 тестовых строк\n","Обработано 10200/20000 тестовых строк\n","Обработано 10400/20000 тестовых строк\n","Обработано 10600/20000 тестовых строк\n","Обработано 10800/20000 тестовых строк\n","Обработано 11000/20000 тестовых строк\n","Обработано 11200/20000 тестовых строк\n","Обработано 11400/20000 тестовых строк\n","Обработано 11600/20000 тестовых строк\n","Обработано 11800/20000 тестовых строк\n","Обработано 12000/20000 тестовых строк\n","Обработано 12200/20000 тестовых строк\n","Обработано 12400/20000 тестовых строк\n","Обработано 12600/20000 тестовых строк\n","Обработано 12800/20000 тестовых строк\n","Обработано 13000/20000 тестовых строк\n","Обработано 13200/20000 тестовых строк\n","Обработано 13400/20000 тестовых строк\n","Обработано 13600/20000 тестовых строк\n","Обработано 13800/20000 тестовых строк\n","Обработано 14000/20000 тестовых строк\n","Обработано 14200/20000 тестовых строк\n","Обработано 14400/20000 тестовых строк\n","Обработано 14600/20000 тестовых строк\n","Обработано 14800/20000 тестовых строк\n","Обработано 15000/20000 тестовых строк\n","Обработано 15200/20000 тестовых строк\n","Обработано 15400/20000 тестовых строк\n","Обработано 15600/20000 тестовых строк\n","Обработано 15800/20000 тестовых строк\n","Обработано 16000/20000 тестовых строк\n","Обработано 16200/20000 тестовых строк\n","Обработано 16400/20000 тестовых строк\n","Обработано 16600/20000 тестовых строк\n","Обработано 16800/20000 тестовых строк\n","Обработано 17000/20000 тестовых строк\n","Обработано 17200/20000 тестовых строк\n","Обработано 17400/20000 тестовых строк\n","Обработано 17600/20000 тестовых строк\n","Обработано 17800/20000 тестовых строк\n","Обработано 18000/20000 тестовых строк\n","Обработано 18200/20000 тестовых строк\n","Обработано 18400/20000 тестовых строк\n","Обработано 18600/20000 тестовых строк\n","Обработано 18800/20000 тестовых строк\n","Обработано 19000/20000 тестовых строк\n","Обработано 19200/20000 тестовых строк\n","Обработано 19400/20000 тестовых строк\n","Обработано 19600/20000 тестовых строк\n","Обработано 19800/20000 тестовых строк\n","Обработано 20000/20000 тестовых строк\n","Мой KNN:\n","  MSE:        0.25\n","  MAE:        0.35\n","  RMSE:       0.50\n","  R²:       0.6479\n","\n","\n","2) Мой LinearRegression с тремя вариантами оптимизаторов (SGD / Momentum / AdaGrad)\n","\n","Тренируем LinearRegression с оптимизатором (SGD)\n","Мой LinearRegression (SGD):\n","  MSE:        0.26\n","  MAE:        0.37\n","  RMSE:       0.51\n","  R²:       0.6252\n","\n","\n","Тренируем LinearRegression с оптимизатором (Momentum)\n","Мой LinearRegression (Momentum):\n","  MSE:        0.26\n","  MAE:        0.37\n","  RMSE:       0.51\n","  R²:       0.6263\n","\n","\n","Тренируем LinearRegression с оптимизатором (AdaGrad)\n","Мой LinearRegression (AdaGrad):\n","  MSE:       42.32\n","  MAE:        5.89\n","  RMSE:       6.51\n","  R²:     -58.9925\n","\n","\n","3) Sklearn KNeighborsRegressor\n","Sklearn KNN:\n","  MSE:        0.25\n","  MAE:        0.35\n","  RMSE:       0.50\n","  R²:       0.6480\n","\n","\n","2) Sklearn LinearRegression\n","Sklearn LR:\n","  MSE:        0.26\n","  MAE:        0.37\n","  RMSE:       0.51\n","  R²:       0.6263\n","\n","\n","СВОДНАЯ ТАБЛИЦА РЕЗУЛЬТАТОВ\n","            Model     MSE    MAE   RMSE       R2\n","          Мой KNN  0.2484 0.3547 0.4984   0.6479\n","     Мой LR (SGD)  0.2644 0.3735 0.5142   0.6252\n","Мой LR (Momentum)  0.2636 0.3733 0.5134   0.6263\n"," Мой LR (AdaGrad) 42.3164 5.8947 6.5051 -58.9925\n","      Sklearn KNN  0.2483 0.3546 0.4983   0.6480\n","       Sklearn LR  0.2636 0.3733 0.5134   0.6263\n","\n","Пример интерпретации результатов\n","\n","Мой KNN:\n","Настоящее значение=21859769.00, Предположение=20605722.60\n","Настоящее значение=9550000.00, Предположение=10831745.90\n","Настоящее значение=4250000.00, Предположение=3625380.80\n","Настоящее значение=2000000.00, Предположение=1096884.51\n","Настоящее значение=9800000.00, Предположение=11361018.04\n","\n","Мой LR (SGD):\n","Настоящее значение=21859769.00, Предположение=15943804.21\n","Настоящее значение=9550000.00, Предположение=18285514.26\n","Настоящее значение=4250000.00, Предположение=3626974.67\n","Настоящее значение=2000000.00, Предположение=1718382.81\n","Настоящее значение=9800000.00, Предположение=6091030.88\n","\n","Мой LR (Momentum):\n","Настоящее значение=21859769.00, Предположение=16018055.06\n","Настоящее значение=9550000.00, Предположение=18138778.02\n","Настоящее значение=4250000.00, Предположение=3617265.13\n","Настоящее значение=2000000.00, Предположение=1727023.66\n","Настоящее значение=9800000.00, Предположение=6076192.94\n","\n","Мой LR (AdaGrad):\n","Настоящее значение=21859769.00, Предположение=733824.34\n","Настоящее значение=9550000.00, Предположение=6236800.17\n","Настоящее значение=4250000.00, Предположение=67510.84\n","Настоящее значение=2000000.00, Предположение=41684.35\n","Настоящее значение=9800000.00, Предположение=4573690.83\n","\n","Sklearn LR:\n","Настоящее значение=21859769.00, Предположение=16018064.07\n","Настоящее значение=9550000.00, Предположение=18138764.41\n","Настоящее значение=4250000.00, Предположение=3617264.13\n","Настоящее значение=2000000.00, Предположение=1727024.84\n","Настоящее значение=9800000.00, Предположение=6076192.19\n","\n","Sklearn KNN:\n","Настоящее значение=21859769.00, Предположение=20605722.60\n","Настоящее значение=9550000.00, Предположение=10831745.90\n","Настоящее значение=4250000.00, Предположение=3625380.80\n","Настоящее значение=2000000.00, Предположение=1096884.51\n","Настоящее значение=9800000.00, Предположение=11361018.04\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_33300\\848985630.py:366: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n","  for t, p in zip(inv_true[:5].ravel(), inv_pred[:5].ravel()):\n"]}],"source":["import math\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.linear_model import LinearRegression as SklearnLinearRegression\n","\n","# Вспомогательные функции\n","\n","# Реализуем расчёт расстояния с помощью функции гаверсинуса\n","def haversine_distance(lat1, lon1, lat2, lon2):\n","    R = 6371.0\n","    lat1 = np.radians(lat1)\n","    lon1 = np.radians(lon1)\n","    lat2 = np.radians(lat2)\n","    lon2 = np.radians(lon2)\n","    dlat = lat2 - lat1\n","    dlon = lon2 - lon1\n","    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n","    c = 2 * np.arcsin(np.sqrt(a))\n","    return R * c\n","\n","# Функция для определения нахождения точки в некотором радиусе. Понадобится для определения нахождения квартиры в Питере или Москве\n","def within_radius(center_lat, center_lon, lat_series, lon_series, radius_km=20.0):\n","    lat = np.array(lat_series, dtype=float)\n","    lon = np.array(lon_series, dtype=float)\n","    mask_valid = ~np.isnan(lat) & ~np.isnan(lon)\n","    res = np.zeros(len(lat), dtype=bool)\n","    if mask_valid.any():\n","        res[mask_valid] = haversine_distance(center_lat, center_lon, lat[mask_valid], lon[mask_valid]) <= radius_km\n","    return res\n","\n","\n","# Метрики\n","#  Подсчёт метрик\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    return mse, mae, rmse, r2\n","\n","# Вывод метрик\n","def print_metrics(model_name, mse, mae, rmse, r2):\n","    print(f\"{model_name}:\")\n","    print(f\"  MSE:  {mse:>10.2f}\")\n","    print(f\"  MAE:  {mae:>10.2f}\")\n","    print(f\"  RMSE: {rmse:>10.2f}\")\n","    print(f\"  R²:   {r2:>10.4f}\")\n","    print()\n","\n","class KNNRegressor:\n","    def __init__(self, n_neighbors=5, metric='euclidean'):\n","        self.n_neighbors = n_neighbors\n","        self.metric = metric\n","        self.X_train = None\n","        self.y_train = None\n","\n","    def fit(self, X, y):\n","        self.X_train = np.array(X, dtype=float)\n","        self.y_train = np.array(y, dtype=float)\n","        return self\n","\n","    def predict(self, X, batch_size=200):\n","        # Батчевая векторная реализация: обрабатываем X по кускам, чтобы не упереться в память. Проблема в том, что компьютер не самый новый, поэтому обработать может не так много. Поэтому ограничим до ~ 100к.\n","        if self.X_train is None or self.y_train is None:\n","            raise ValueError(\"Модель не отфильтрована.\")\n","        X = np.array(X, dtype=float)\n","        n = X.shape[0]\n","        preds = []\n","        for start in range(0, n, batch_size):\n","            end = min(start + batch_size, n)\n","            Xb = X[start:end]\n","            # вычисление может быть тяжёлым, но при разумном batch_size подходит\n","            dists = np.sqrt(np.sum((Xb[:, np.newaxis, :] - self.X_train[np.newaxis, :, :]) ** 2, axis=2))\n","            # argpartition быстро найдёт k ближайших индексов\n","            idx = np.argpartition(dists, self.n_neighbors, axis=1)[:, :self.n_neighbors] # По сути частичная сортировка\n","            preds_batch = np.mean(self.y_train[idx], axis=1)\n","            preds.append(preds_batch)\n","            print(f\"Обработано {end}/{n} тестовых строк\")\n","        return np.concatenate(preds, axis=0)\n","\n","# Реализуем класс нашей линейной регрессии\n","class LinearRegression:\n","    def __init__(self, learning_rate=0.01, optimization='SGD', epsilon=1e-8, decay_rate=0.9, max_iter=1000):\n","        self.learning_rate = learning_rate\n","        self.optimization = optimization\n","        self.epsilon = epsilon\n","        self.decay_rate = decay_rate\n","        self.max_iter = max_iter\n","        self.weights = None\n","        self.bias = None\n","\n","    # Основная функция, которая занимается обучением нашей модели.\n","    def fit(self, X, y):\n","        X = np.array(X, dtype=float)\n","        y = np.array(y, dtype=float).reshape(-1, 1)\n","\n","        n_samples, n_features = X.shape\n","        self.weights = np.zeros((n_features, 1))\n","        self.bias = 0.0\n","\n","        # Переменные для Momentum и AdaGrad\n","        v_w = np.zeros_like(self.weights)\n","        v_b = 0.0\n","        G_w = np.zeros_like(self.weights)\n","        G_b = 0.0\n","\n","        # Итеративно обновляем веса, чтобы минимизировать ошибку\n","        for i in range(self.max_iter):\n","            # Предсказание\n","            y_pred = X.dot(self.weights) + self.bias\n","\n","            # Градиенты\n","            error = y_pred - y\n","            dw = (2 / n_samples) * X.T.dot(error)\n","            db = (2 / n_samples) * np.sum(error)\n","\n","            # Выбор оптимизатора\n","            # Обычный градиентный спуск\n","            if self.optimization == 'SGD':\n","                self.weights -= self.learning_rate * dw\n","                self.bias -= self.learning_rate * db\n","\n","            # Градиентный спуск с инерцией\n","            elif self.optimization == 'Momentum':\n","                v_w = self.decay_rate * v_w + self.learning_rate * dw\n","                v_b = self.decay_rate * v_b + self.learning_rate * db\n","                self.weights -= v_w\n","                self.bias -= v_b\n","\n","            # Шаг должен адаптироваться каждый раз, становясь всё меньше и меньше\n","            elif self.optimization == 'AdaGrad':\n","                G_w += dw ** 2\n","                G_b += db ** 2\n","                self.weights -= (self.learning_rate / (np.sqrt(G_w) + self.epsilon)) * dw\n","                self.bias -= (self.learning_rate / (np.sqrt(G_b) + self.epsilon)) * db\n","\n","            # else:\n","            #     raise ValueError(f\"Unknown optimization method: {self.optimization}\")\n","\n","            # Контроль сходимости\n","            # if i % (self.max_iter // 10) == 0 or i == self.max_iter - 1:\n","            #     mse = np.mean(error ** 2)\n","            #     print(f\"Iter {i:4d} | MSE: {mse:.6f}\")\n","\n","        return self\n","\n","    def predict(self, X): # Предсказание\n","        X = np.array(X, dtype=float)\n","        return X.dot(self.weights) + self.bias\n","\n","# Загрузка и предобработка\n","print(\"Читаем датасет...\")\n","df = pd.read_csv('input_data.csv', delimiter=';')\n","\n","# 1) Добавляем признаки is_Moscow и is_Saint_Peterburg (20 км)\n","print(\"Добавляем is_Moscow и is_Saint_Peterburg ...\")\n","if 'geo_lat' not in df.columns:\n","    df['geo_lat'] = np.nan\n","if 'geo_lon' not in df.columns:\n","    df['geo_lon'] = np.nan\n","\n","# Проверяем на нахождение в радиусе 20 км от Питера и Москвы.\n","df['is_Moscow'] = within_radius(55.75583, 37.61778, df['geo_lat'], df['geo_lon'], radius_km=20.0)\n","df['is_Saint_Peterburg'] = within_radius(59.93863, 30.31413, df['geo_lat'], df['geo_lon'], radius_km=20.0)\n","\n","# 2) Относительный этаж (relative_location)\n","# Если levels == 0 или NaN -> relative = 0. Вообще, по логике этажи не могут быть нулевыми, но на всякий случай проверим.\n","if 'level' not in df.columns:\n","    df['level'] = np.nan\n","if 'levels' not in df.columns:\n","    df['levels'] = np.nan\n","df['relative_location'] = np.where((df['levels'] > 0) & (~df['levels'].isna()), df['level'] / df['levels'], 0.0)\n","\n","# 3) Дни от первого наблюдения\n","# преобразуем дату в datetime, считаем дни от минимальной даты в датасете. Честно признаться, особого смысла в этом нет, но задание есть задание. Другая интерпретация - количество дней с первого наблюдения за каждым конкретным объектом,\n","# но для этого во-первых понадобилось бы наличие таких наблюдений, во-вторыых признак, по которому каждую квартиру можно было бы уникально идентифицировать, но такого признака нет.\n","if 'date' in df.columns:\n","    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n","    min_date = df['date'].min()\n","    df['days_from_first'] = (df['date'] - min_date).dt.days.fillna(0).astype(int)\n","else:\n","    df['days_from_first'] = 0\n","\n","# Удалим date после добавления новых признаков\n","if 'date' in df.columns:\n","    df = df.drop(columns=['date'])\n","\n","# 4) Удаляем ненужные колонки\n","to_drop = ['geo_lat', 'geo_lon', 'object_type', 'postal_code', 'street_id', 'id_region', 'house_id']\n","for col in to_drop:\n","    if col in df.columns:\n","        df.drop(columns=[col], inplace=True)\n","\n","# 5) Приведение rooms: в задании -1 означает апартаменты -> можно заменить на отдельный флаг. Делаем так, чтобы значения -1 не портили нашу модель\n","if 'rooms' in df.columns:\n","    df['is_apartment'] = (df['rooms'] == -1)\n","    # при необходимости: заменить -1 на 0 или NaN\n","    df['rooms'] = df['rooms'].replace(-1, 0)\n","\n","# Предварительная фильтрация / подвыборка\n","# Для функционирования используем подвыборку для KNN и тестирования, но оставляем опцию обучать библиотечные на всём\n","MAX_SAMPLE_FOR_OUR_KNN = 100_000\n","if len(df) > MAX_SAMPLE_FOR_OUR_KNN:\n","    print(f\"\\nДатасет большеват ({len(df):,}). Для моего KNN использую первые {MAX_SAMPLE_FOR_OUR_KNN:,} строк.\")\n","    df_small = df.head(MAX_SAMPLE_FOR_OUR_KNN).copy()\n","else:\n","    df_small = df.copy()\n","\n","# Готовим X, y\n","\n","# Определяем числовные и категориальные признаки\n","numeric_features = ['level', 'levels', 'rooms', 'area', 'kitchen_area', 'relative_location', 'days_from_first']\n","categorical_features = ['building_type', 'is_Moscow', 'is_Saint_Peterburg', 'is_apartment']\n","\n","print(f\"\\nЧисловые признаки: {len(numeric_features)}\")\n","print(f\"Категориальные признаки: {len(categorical_features)}\")\n","\n","# Удаляем строки с пропусками в критичных числовых признаках и таргете\n","required_for_drop = numeric_features + ['price']\n","df_small_clean = df_small.dropna(subset=required_for_drop)\n","\n","X_num = df_small_clean[numeric_features].copy()\n","X_cat = df_small_clean[categorical_features].copy()\n","y = df_small_clean['price'].copy()\n","\n","# Диагностика целевой переменной\n","print(\"\\nОписание целевой переменной:\")\n","print(y.describe())\n","\n","# OneHotEncoding категориальных признаков\n","if len(categorical_features) > 0:\n","    ohe = OneHotEncoder(drop='first', handle_unknown='ignore') # drop='first' чтобы избежать мультиколлинеарности (сильная зависимость объектов между собой, нам такой лишний груз не нужен)\n","    encoded = ohe.fit_transform(X_cat)\n","\n","    encoded = encoded.toarray()\n","\n","    try:\n","        ohe_names = ohe.get_feature_names_out(categorical_features)\n","    except Exception as e:\n","        print(e)\n","\n","    X_encoded = pd.DataFrame(encoded, columns=ohe_names, index=X_num.index) # Создаём датафрейм с закодированными признаками\n","    X_pre = pd.concat([X_num, X_encoded], axis=1)\n","else:\n","    X_pre = X_num.copy() # Если нет категорий, то просто берём числовые признаки\n","\n","# Здесь мы просматриваем таблицу на наличие строк, в которых у каких-либо признаков есть пропуски. Если они есть - удаляем, если нет - оставляем. Делается это\n","#  с помощью создания булевой таблицы, состоящей из true и false, и последующим фильтром\n","mask_notna = X_pre.notna().all(axis=1)\n","X_pre = X_pre.loc[mask_notna]\n","y = y.loc[mask_notna]\n","\n","# Нормализация числовых признаков. Это нужно для повышения качества модели.\n","# Таким образом мы приводим числовые признаки к одному масштабу\n","scaler = StandardScaler()\n","num_cols_present = [c for c in numeric_features if c in X_pre.columns]\n","if len(num_cols_present) > 0:\n","    X_pre[num_cols_present] = scaler.fit_transform(X_pre[num_cols_present])\n","\n","# Логарифмируем целевую переменную, это нужно для того, чтобы в будущем уменьшить влияение выбросов - то есть слишком низких цен (в датасете есть цена в 0, лол) или слишком высоких.\n","LOG_TARGET = True\n","if LOG_TARGET:\n","    y_trans = np.log1p(y)\n","else:\n","    y_trans = y.values\n","\n","# Разделим на обучающую и тестовую выборку\n","X_train, X_test, y_train, y_test = train_test_split(X_pre, y_trans, test_size=0.2, random_state=42)\n","print(f\"\\nОбучающая выборка: {X_train.shape}, Тестовая выборка: {X_test.shape}\")\n","\n","\n","# Запуск моделей\n","\n","results = []\n","# Важно отметить, что значения метрик такие, какие они есть, потому что значения цены логарифмировалось. То есть значение mse и других метрик, которые мы видим, относятся не к рублям по факту, а к логарифму 1+p\n","# 1) Наш KNN на подвыборке (если X_train не слишком большой)\n","print(\"\\n1) Мой KNN on на \\\"маленькой\\\" подвыборке\")\n","try:\n","    our_knn = KNNRegressor(n_neighbors=5)\n","    our_knn.fit(X_train.values, y_train.values)\n","    our_knn_pred = our_knn.predict(X_test.values, batch_size=200)\n","    our_knn_mse, our_knn_mae, our_knn_rmse, our_knn_r2 = calculate_metrics(y_test, our_knn_pred)\n","    print_metrics(\"Мой KNN\", our_knn_mse, our_knn_mae, our_knn_rmse, our_knn_r2)\n","    results.append(('Мой KNN', our_knn_mse, our_knn_mae, our_knn_rmse, our_knn_r2))\n","except MemoryError as e:\n","    print(\"Ошибка помяти:\", e)\n","\n","# 2) Мой LinearRegression\n","print(\"\\n2) Мой LinearRegression с тремя вариантами оптимизаторов (SGD / Momentum / AdaGrad)\")\n","\n","our_lr_sgd_pred = None\n","our_lr_momentum_pred = None\n","our_lr_adagrad_pred = None\n","for opt in ['SGD', 'Momentum', 'AdaGrad']:\n","    print(f\"\\nТренируем LinearRegression с оптимизатором ({opt})\")\n","    our_lr = LinearRegression(\n","        learning_rate=0.1,\n","        optimization=opt,\n","        max_iter=1000\n","    )\n","\n","    our_lr.fit(X_train, y_train)\n","    our_lr_pred = our_lr.predict(X_test)\n","\n","    if opt == 'SGD':\n","        our_lr_sgd_pred = our_lr_pred\n","    elif opt == 'Momentum':\n","        our_lr_momentum_pred = our_lr_pred\n","    elif opt == 'AdaGrad':\n","        our_lr_adagrad_pred = our_lr_pred\n","\n","    # вычисляем метрики\n","    our_lr_mse, our_lr_mae, our_lr_rmse, our_lr_r2 = calculate_metrics(y_test, our_lr_pred)\n","\n","    # выводим и добавляем в результаты\n","    print_metrics(f\"Мой LinearRegression ({opt})\", our_lr_mse, our_lr_mae, our_lr_rmse, our_lr_r2)\n","    results.append((f\"Мой LR ({opt})\", our_lr_mse, our_lr_mae, our_lr_rmse, our_lr_r2))\n","\n","\n","# 3) Sklearn KNN\n","print(\"\\n3) Sklearn KNeighborsRegressor\")\n","sk_knn = KNeighborsRegressor(n_neighbors=5, algorithm='ball_tree', n_jobs=-1)\n","# NOTE: если X_train очень большой, этот fit может занять время и память, но он гораздо оптимизированней\n","sk_knn.fit(X_train, y_train)\n","sk_knn_pred = sk_knn.predict(X_test)\n","sk_knn_mse, sk_knn_mae, sk_knn_rmse, sk_knn_r2 = calculate_metrics(y_test, sk_knn_pred)\n","print_metrics(\"Sklearn KNN\", sk_knn_mse, sk_knn_mae, sk_knn_rmse, sk_knn_r2)\n","results.append(('Sklearn KNN', sk_knn_mse, sk_knn_mae, sk_knn_rmse, sk_knn_r2))\n","\n","# 4) Sklearn LinearRegression\n","print(\"\\n2) Sklearn LinearRegression\")\n","sk_lr = SklearnLinearRegression()\n","sk_lr.fit(X_train, y_train)\n","sk_lr_pred = sk_lr.predict(X_test)\n","sk_lr_mse, sk_lr_mae, sk_lr_rmse, sk_lr_r2 = calculate_metrics(y_test, sk_lr_pred)\n","print_metrics(\"Sklearn LR\", sk_lr_mse, sk_lr_mae, sk_lr_rmse, sk_lr_r2)\n","results.append(('Sklearn LR', sk_lr_mse, sk_lr_mae, sk_lr_rmse, sk_lr_r2))\n","\n","# Сводная таблица результатов. Опять же, важно отметить, что результаты представлены в логарифмическом масштабе\n","results_df = pd.DataFrame(results, columns=['Model', 'MSE', 'MAE', 'RMSE', 'R2'])\n","print(\"\\nСВОДНАЯ ТАБЛИЦА РЕЗУЛЬТАТОВ\")\n","print(results_df.to_string(index=False, float_format='%.4f'))\n","\n","if LOG_TARGET:\n","    print(\"\\nПример интерпретации результатов\")\n","    inv_true = np.expm1(y_test)\n","\n","    models_to_check = [\n","        ('Мой KNN', our_knn_pred),\n","        ('Мой LR (SGD)', our_lr_sgd_pred),\n","        ('Мой LR (Momentum)', our_lr_momentum_pred),\n","        ('Мой LR (AdaGrad)', our_lr_adagrad_pred),\n","        ('Sklearn LR', sk_lr_pred),\n","        ('Sklearn KNN', sk_knn_pred),\n","    ]\n","\n","    for name, preds in models_to_check:\n","        print(f\"\\n{name}:\")\n","        inv_pred = np.expm1(preds)\n","        for t, p in zip(inv_true[:5].ravel(), inv_pred[:5].ravel()):\n","            print(f\"Настоящее значение={t:.2f}, Предположение={p:.2f}\")"]},{"cell_type":"code","execution_count":null,"id":"ca6c1aa0-eee9-48f9-b0b2-23ec949b43d4","metadata":{"id":"ca6c1aa0-eee9-48f9-b0b2-23ec949b43d4"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}