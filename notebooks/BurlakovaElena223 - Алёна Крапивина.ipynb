{"cells":[{"cell_type":"markdown","metadata":{"id":"udk8HMvTGTcw"},"source":["#**Машинное обучение ИБ-2024**\n","\n","#**Домашнее задание 2.**\n","#Классификация, KNN, LogReg, SVC."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"3SlSvjUyIx6P","executionInfo":{"status":"ok","timestamp":1730412383860,"user_tz":-180,"elapsed":6016,"user":{"displayName":"Даниил Бураков","userId":"09897088617103092800"}}},"outputs":[],"source":["from typing import Tuple, List\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","%matplotlib inline\n","\n","sns.set(style=\"darkgrid\")"]},{"cell_type":"markdown","metadata":{"id":"anNYyOmryCU-"},"source":["## **Теоретическая Часть**"]},{"cell_type":"markdown","metadata":{"id":"gOsiAL0yHPZc"},"source":["Мы рассматриваем задачу бинарной классификации. Для прогнозирования мы хотели бы использовать модель логистической регрессии. Для регуляризации мы добавляем комбинацию штрафов в размере $l_2$ и $l_1$ (Elastic Net).\n","\n","Каждый объект в обучающем наборе данных индексируется с помощью $i$ и описывается парой: объекты $x_i\\in\\mathbb{R}^{K}$ и двоичные метки $y_i$. Модель параметризуется со смещением $w_0\\in\\mathbb{R}$ и весами $w\\in\\mathbb{R}^K$.\n","\n","Задача оптимизации в отношении $w_0, w$ заключается в следующем (Elastic Net Loss):\n","\n","$$L(w, w_0) = \\frac{1}{N} \\sum_{i=1}^N \\ln(1+\\exp(-y_i(w^\\top x_i+w_0))) + \\gamma \\|w\\|_1 + \\beta \\|w\\|_2^2$$.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VDvxlzjaHtBv"},"source":["Градиенты функции потерь логистической регрессии представлены ниже:"]},{"cell_type":"markdown","metadata":{"id":"PeDXXb9kHqiE"},"source":["$$dL(w, w_0)/ dw = -\\frac{1}{N}  \\frac{X*y^\\top}{1 + \\exp(y (Xw+w_0)))} + \\gamma * sign(w) + 2 * beta * w$$\n","\n","$$dL(w, w_0)/ dw_0 = -\\frac{1}{N}  \\frac{y}{1 + \\exp(y*(Xw+w_0)))}$$"]},{"cell_type":"markdown","metadata":{"id":"StAKNPmaIj5C"},"source":["#### 1. [0.5 Балл] Реализуйте функцию, выдающий значение функции потерь логичтической регрессии:"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"_z1jsC30GSii","executionInfo":{"status":"ok","timestamp":1730412387096,"user_tz":-180,"elapsed":286,"user":{"displayName":"Даниил Бураков","userId":"09897088617103092800"}}},"outputs":[],"source":["def loss(X, y, w: List[float], w0: float, gamma=1., beta=1.) -> float:\n","  \"\"\"\n","  Функция потерь логистической регрессии.\n","\n","  Args:\n","    X: Матрица признаков (N x D).\n","    y: Вектор меток (N x 1).\n","    w: Вектор весов (D x 1).\n","    w0: Смещение.\n","    gamma: Параметр регуляризации L1.\n","    beta: Параметр регуляризации L2.\n","\n","  Returns:\n","    Значение функции потерь.\n","  \"\"\"\n","  N = X.shape[0]\n","  y_pred = 1 / (1 + np.exp(-y * (X @ w + w0)))\n","  loss_val = -np.sum(np.log(y_pred)) / N\n","  loss_val += gamma * np.sum(np.abs(w)) + beta * np.sum(w**2)\n","  return loss_val\n","#  pass"]},{"cell_type":"markdown","metadata":{"id":"WIlZHGAuIqEP"},"source":["#### 2. [0.5 Балл] Реализуйте функцию, которая будет возвращать градиенты весов вашей модели Логистической регрессии:"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"p7Pg4o4_IpFs","executionInfo":{"status":"ok","timestamp":1730412403809,"user_tz":-180,"elapsed":273,"user":{"displayName":"Даниил Бураков","userId":"09897088617103092800"}}},"outputs":[],"source":["def get_grad(X, y, w: List[float], w0: float, gamma=1., beta=1.) -> Tuple[List[float], float]:\n","    '''\n","    :param X: np.ndarray of shape (n_objects, n_features) -- matrix objects-features\n","    :param y: np.ndarray of shape (n_objects,) -- vector of the correct answers\n","    :param w: np.ndarray of shape (n_feratures,) -- the weights\n","    :param w0: intercept\n","    :param gamma: penalty hyperparameter of L1-regularization\n","    :param beta: penalty hyperparameter of L2-regularization\n","\n","    '''\n","\n","\n","    \"\"\"\n","    Вычисляет градиенты весов и смещения для логистической регрессии.\n","\n","    Args:\n","        X: Матрица признаков (N x D).\n","        y: Вектор меток (N x 1).\n","        w: Вектор весов (D x 1).\n","        w0: Смещение.\n","        gamma: Параметр регуляризации L1.\n","        beta: Параметр регуляризации L2.\n","\n","    Returns:\n","        Кортеж, содержащий:\n","        - градиент весов (D x 1)\n","        - градиент смещения (1 x 1)\n","    \"\"\"\n","    N = X.shape[0]\n","    y_pred = 1 / (1 + np.exp(-y * (X @ w + w0)))\n","\n","    # Градиент весов\n","    grad_w = -np.sum((X.T * y * (1 - y_pred)) / N, axis=1) + gamma * np.sign(w) + 2 * beta * w\n","    grad_w = -np.sum((X.T * y * (1 - y_pred)) / N, axis=1) + gamma * np.sign(w) + 2 * beta * w\n","\n","\n","    # Градиент смещения\n","    grad_w0 = -np.sum(y * (1 - y_pred)) / N\n","\n","    return grad_w.tolist(), grad_w0\n","#    pass"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Q9SndxzbI8yy","executionInfo":{"status":"ok","timestamp":1730412406738,"user_tz":-180,"elapsed":286,"user":{"displayName":"Даниил Бураков","userId":"09897088617103092800"}}},"outputs":[],"source":["# код для проверки\n","\n","np.random.seed(42)\n","X = np.random.multivariate_normal(np.arange(5), np.eye(5), size=10)\n","y = np.random.binomial(1, 0.42, size=10)\n","w, w0 = np.random.normal(size=5), np.random.normal()\n","\n","grad_w, grad_w0 = get_grad(X, y, w, w0)\n","assert(np.allclose(grad_w,\n","                   [-2.73262076, -1.87176281, 1.30051144, 2.53598941, -2.71198109],\n","                   rtol=1e-2) & \\\n","       np.allclose(grad_w0,\n","                   -0.2078231418067844,\n","                   rtol=1e-2)\n",")"]},{"cell_type":"markdown","metadata":{"id":"3gINHTOgJaS7"},"source":["####  3. [1 Балл]  Реализуйте класс для модели логистической регрессии, используя выше написанные функции:"]},{"cell_type":"markdown","metadata":{"id":"Xo-IJWGTDUQH"},"source":["Модель должна обучаться методом SGD."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FfwNPBafJSVT"},"outputs":[],"source":["from sklearn.base import BaseEstimator, ClassifierMixin\n","from sklearn.metrics import roc_curve"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"43z5BoIRJjV9"},"outputs":[],"source":["class Logit(BaseEstimator, ClassifierMixin):\n","    def __init__(self, beta=1.0, gamma=1.0, lr=1e-2, tolerance=1e-8, max_iter=1000, random_state=42):\n","        '''\n","        betta: penalty hyperparameter of L2-regularization\n","        gamma: penalty hyperparameter of L1-regularization\n","        tolerance: minimal allowed movement in each iteration\n","        lr: determines the step size at each iteration\n","        max_iter: maximum number of iterations taken for the solvers to converge\n","\n","        '''\n","        \"\"\"\n","        Инициализирует модель логистической регрессии.\n","\n","        Args:\n","            beta: Параметр регуляризации L2.\n","            gamma: Параметр регуляризации L1.\n","            lr: Шаг обучения.\n","            tolerance: Порог для остановки градиентного спуска.\n","            max_iter: Максимальное количество итераций.\n","            random_state: Случайное начальное значение.\n","        \"\"\"\n","        self.beta = beta\n","        self.gamma = gamma\n","        self.lr = lr\n","        self.tolerance = tolerance\n","        self.max_iter = max_iter\n","        self.random_state = random_state\n","        self.w = None\n","        self.w0 = None\n","\n","\n","    def fit(self, X, y):\n","        \"\"\"\n","        Обучает модель логистической регрессии.\n","\n","        Args:\n","            X: Матрица признаков (N x D).\n","            y: Вектор меток (N x 1).\n","        \"\"\"\n","        np.random.seed(self.random_state)\n","        self.w = np.random.normal(size=X.shape[1])\n","        self.w0 = np.random.normal()\n","\n","        for _ in range(self.max_iter):\n","            grad_w, grad_w0 = get_grad(X, y, self.w, self.w0, self.gamma, self.beta)\n","\n","            # Обновление весов\n","            self.w -= self.lr * grad_w\n","            self.w0 -= self.lr * grad_w0\n","\n","            # Проверка на сходимость\n","            if np.linalg.norm(grad_w) < self.tolerance and np.abs(grad_w0) < self.tolerance:\n","                break\n","\n","        return self\n","\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Function that returns the vector of predicted labels for each object from X\n","        Предсказывает метки для новых объектов.\n","\n","        Args:\n","            X: Матрица признаков (N x D).\n","\n","        Returns:\n","            Вектор предсказанных меток (N x 1).\n","        \"\"\"\n","        y_pred = 1 / (1 + np.exp(-(X @ self.w + self.w0)))\n","        return (y_pred > 0.5).astype(int)\n","\n","\n","    def predict_proba(self, X):\n","        \"\"\"\n","        Function that estimates probabilitie\n","        Предсказывает вероятности принадлежности к классу.\n","\n","        Args:\n","            X: Матрица признаков (N x D).\n","\n","        Returns:\n","            Вектор предсказанных вероятностей (N x 1).\n","        \"\"\"\n","        y_pred = 1 / (1 + np.exp(-(X @ self.w + self.w0)))\n","        return y_pred\n","\n","#        pass\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y0dzDEMFJmR3"},"outputs":[],"source":["# этот код менять не надо!\n","from sklearn.datasets import make_classification\n","X, y = make_classification(n_samples=1800, n_features=2, n_redundant=0, n_informative=2,\n","                               random_state=42, n_clusters_per_class=1)"]},{"cell_type":"markdown","metadata":{"id":"fedP3pyAs9Xk"},"source":["####  4. [0.5 Балл]  Реализуйте функцию, которая отрисовывает объекты вашего датасета, их метки и разделяющую гиперплоскость, полученную от Логистической регрессии (пример того, что должно получиться ниже):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LVMUvlkpJpvu"},"outputs":[],"source":["def plot_decision_boundary(model, X, y):\n","    \"\"\"\n","    Отрисовывает объекты, их метки и разделяющую гиперплоскость.\n","\n","    Args:\n","        model: Обученная модель логистической регрессии.\n","        X: Матрица признаков (N x D).\n","        y: Вектор меток (N x 1).\n","    \"\"\"\n","    # Проверка, что модель обучена\n","    if model.w is None or model.w0 is None:\n","        raise ValueError(\"Модель должна быть обучена перед отрисовкой границы решения.\")\n","\n","    # Отрисовка объектов\n","    plt.scatter(X[y == 0, 0], X[y == 0, 1], c='blue', label='Класс 0')\n","    plt.scatter(X[y == 1, 0], X[y == 1, 1], c='red', label='Класс 1')\n","\n","    # Вычисление координат разделяющей гиперплоскости\n","    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n","    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n","    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n","    Z = 1 / (1 + np.exp(-(xx * model.w[0] + yy * model.w[1] + model.w0)))\n","    Z = Z > 0.5\n","\n","    # Отрисовка разделяющей гиперплоскости\n","    plt.contour(xx, yy, Z, colors='green', linewidths=2)\n","\n","    # Настройка графика\n","    plt.xlabel('Признак 1')\n","    plt.ylabel('Признак 2')\n","    plt.title('Разделяющая гиперплоскость')\n","    plt.legend()\n","    plt.show()\n","#    pass"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":434},"id":"PISzKE_xJsZh","outputId":"823cc044-fa7f-4e4b-bc74-a853d8d15c5b"},"outputs":[{"ename":"TypeError","evalue":"can't multiply sequence by non-int of type 'float'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Logit(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m y[y \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m plot_decision_boundary(model, X, y)\n","Cell \u001b[1;32mIn[7], line 48\u001b[0m, in \u001b[0;36mLogit.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     45\u001b[0m grad_w, grad_w0 \u001b[38;5;241m=\u001b[39m get_grad(X, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw0, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Обновление весов\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgrad_w\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw0 \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;241m*\u001b[39m grad_w0\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Проверка на сходимость\u001b[39;00m\n","\u001b[1;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"]}],"source":["model = Logit(0,0)\n","y[y == 0] = -1\n","model.fit(X, y)\n","plot_decision_boundary(model, X, y)"]},{"cell_type":"markdown","metadata":{"id":"4lyS4dNXPYr1"},"source":["#### 5. [0.5 Балл] Для предыдущей задачи отобразите на графике, как изменяется значение функция потерь от номера итерации."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aTj-XMOvZ2YG"},"outputs":[],"source":["def plot_loss_history(model):\n","    pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SJeDlYsJt8W0"},"outputs":[],"source":["plot_loss_history(model)"]},{"cell_type":"markdown","metadata":{"id":"3zHxhSSnt7Iw"},"source":["#### 6. [2 Балл] Для данных, на которых тестировали модель Логистической регрессии, заиспользуйте модель SVC из библиотеки sklearn. Попробуйте различные ядра (kernel) и различные коэфициенты C. Посмотрите на метрики, которые мы обсуждали на занятии (Acc, Precision, Recall, AUC-ROC, F1-Score)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qpwzcThrvCyU"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"tAyn5WAYvefO"},"source":["#### 7. [2 Балл] Реализуйте класс KNNClassifier, который должен реализовывать классификацию путем нахождения k ближайших соседей. В методе predict_proba Вам необходимо выдавать вектор вероятностей для каждого объекта, который означает, что объект является экземпляром i-го класса с p_i вероятностью. Протестируйте Ваш класс на данных, сгенерированных выше, посмотрите на метрики (Acc, Precision, Recall, AUC-ROC, F1-Score)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eFNJLQ_Vv4dU"},"outputs":[],"source":["class KNNClassifier:\n","    def __init__(self, n_neighbors=5, metric='euclidean'):\n","      ...\n","\n","    def fit(self, X, y):\n","      ...\n","\n","    def predict(self, X):\n","      ...\n","\n","    def predict_proba(self, X):\n","      ..."]},{"cell_type":"markdown","metadata":{"id":"RPABb_kMysd6"},"source":["## **Практическая часть**"]},{"cell_type":"markdown","metadata":{"id":"q8vRW2QayxIX"},"source":["В этом задании мы будем работать с Датасетом Fashion Mnist. Это датасет, который представляет изображения одного канала с различными типами одежды. Вам необходимо провести полный пайплайн обучения моделей (KNN и Logreg), которые вы можете импортировать из библиотеки sklearn."]},{"cell_type":"markdown","metadata":{"id":"BePXBACs0Z2F"},"source":["#### 8. [0 Балл] Импортируйте датафрейм из csv файла. Поделите выборку следующим образом - :50000 (Train) и 50000: (Test)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Elrow43kywfP"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"_3X27C9W8vyx"},"source":["#### 9. [0.5 Балл] Визуализируйте некоторые из объектов датасета. В колонках отображены яркости пикселей, которые представляют из себя изображения Fashion Mnist. С помощью matplotlib визуализируйте по одному представителю каждого класса."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KanzBBUL9Svb"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"xfdGxPq19ef0"},"source":["#### 10. [0.5 Балл] Отнормируйте признаки в датасете, попробуйте два варианта StandartScaller и MinMaxScaller."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TOpmPYll-Fu1"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"0OMKYo3K-IQ2"},"source":["#### 10. [2 Балл] Проведите эксперименты: для моделей KNeighborsClassifier и LogisticRegression подберите гиперпараметры с помощью GridSerchCV (минимум 5 фолдов). Получите качество моделей на тестовой выборке. Основная метрика в данном задании будет accuracy. Сравните эти две модели. Какая модель показывает лучшее качество, предположите почему и напишите ответ.\n","\n","**NB!**: в задании нужно подбирать несколько гиперпараметров по сетке. Какие гиперпараметры подбирать - решаете Вы сами. Обязательно обоснуйте, почему и какие параметры Вы подбираете! Например, подбор только гиперпараметра C в LogisticRegression не будет засчитываться как решение данного задания! Попытайтесь серьезно отнестись к нему, будто вы за это получите зарплату 300к."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9V50Z-d5_GFG"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"MlMatXPK_56f"},"source":["## **Бонусы**"]},{"cell_type":"markdown","metadata":{"id":"eSP3Qx8FAFsA"},"source":["#### Задача 1. [1 Балл] У Вас есть датасет с 10**4 объектами. У всех объектов два признака и все они одинаковые у всех объектов. Однако, 5000 - отрицательного класса и 5000 - положительного класса. Вы запускате Логистическую регрессию для классификации на данном датасете. Что Вы получите в итоге обучения данной модели на SGD? Ответ обоснуйте."]},{"cell_type":"markdown","metadata":{"id":"W4qCiGesA258"},"source":["#### Задача 2. [1 Балл] При классификации Fashion Mnist модель Логистической регрессии на обучении многоклассовой классификации методом One-VS-All у Вас получилось k классификаторов. Изобразите веса ваших полученных моделей как изображения в matplotlib. Возможно, модель выучила какие-то графические паттерны в данных? Ответ обоснуйте."]},{"cell_type":"markdown","metadata":{"id":"fwO_-__KB2Zy"},"source":["#### Задача 3. [1 Балл] В задаче классификации Fashion Mnist Вы попытались выбить какой-то accuracy. Для получения бонусного балла Вам нужно на той же самой выборке получить значение метрики accuracy > 0.87 на тесте (Тестовую выборку менять нельзя, но обучающую можно). Какими моделями и методами Вы это будете делать - на Ваше усмотрение, но **нельзя использовать никакие нейронные сети**. Необходимо получить модель машинного обучения, выполняющую эту задачу."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y5PSUQ7qEJOW"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}