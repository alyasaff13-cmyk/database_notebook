{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O21kEVTrOeVZ"
      },
      "source": [
        "#**Машинное обучение ИБ-2024**\n",
        "\n",
        "#**Домашнее задание 1.**\n",
        "#Регрессия, KNN, LinearRegression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ2TkkhkQH-H"
      },
      "source": [
        "В данной домашней работе мы будем строить модели для предсказания цены квартиры в России. Ниже приведено описание некоторых колонок набора данных.\n",
        "\n",
        "date - дата публикации объявления\n",
        "\n",
        "price - цена в рублях\n",
        "\n",
        "level- этаж, на котором находится квартира\n",
        "\n",
        "levels - количество этажей в квартире\n",
        "\n",
        "rooms - количество комнат в квартире. Если значение -1, то квартира считается апартаментами.\n",
        "\n",
        "area - площадь квартиры.\n",
        "\n",
        "kitchen_area - площадь кухни.\n",
        "\n",
        "geo_lat - Latitude\n",
        "\n",
        "geo_lon - Longitude\n",
        "\n",
        "building_type - материал застройки. 0 - Don't know. 1 - Other. 2 - Panel. 3 - Monolithic. 4 - Brick. 5 - Blocky. 6 - Wooden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu_nZBPaRPTA"
      },
      "source": [
        "#Часть 0. Начало работы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuPeg4isP_ok"
      },
      "source": [
        "Для начала работы с данными импортируем библиотеки, которые понадобятся в данном задании."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AeSkfkF7_Fkp"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LinearRegression as SkLinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvnX1OmGRMlU"
      },
      "source": [
        "Загрузим библиотеку folium для отображения данных на карте по координатам."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsEgwmPy_Pwn",
        "outputId": "f260763c-1973-4141-b506-ad27040e547d"
      },
      "outputs": [],
      "source": [
        "#!pip install folium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqWPnWJpRqhS"
      },
      "source": [
        "Загрузим данные из csv файла в датафрейм."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "pHgoLbrz_Uaf",
        "outputId": "973f2842-34a6-4297-b6e6-f6834c644ba7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Данные загружены. Размер: (11358150, 15)\n",
            "Колонки: ['date', 'price', 'level', 'levels', 'rooms', 'area', 'kitchen_area', 'geo_lat', 'geo_lon', 'building_type', 'object_type', 'postal_code', 'street_id', 'id_region', 'house_id']\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Загрузка данных вместо распаковки \n",
        "df = pd.read_csv('input_data.csv', sep=';')\n",
        "print(f\"Данные загружены. Размер: {df.shape}\")\n",
        "print(f\"Колонки: {df.columns.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Первые 5 строк данных:\n",
            "         date     price  level  levels  rooms  area  kitchen_area    geo_lat  \\\n",
            "0  2021-01-01   2451300     15      31      1  30.3           0.0  56.780112   \n",
            "1  2021-01-01   1450000      5       5      1  33.0           6.0  44.608154   \n",
            "2  2021-01-01  10700000      4      13      3  85.0          12.0  55.540060   \n",
            "3  2021-01-01   3100000      3       5      3  82.0           9.0  44.608154   \n",
            "4  2021-01-01   2500000      2       3      1  30.0           9.0  44.738685   \n",
            "\n",
            "     geo_lon  building_type  object_type  postal_code  street_id  id_region  \\\n",
            "0  60.699355              0            2     620000.0        NaN         66   \n",
            "1  40.138381              0            0     385000.0        NaN          1   \n",
            "2  37.725112              3            0     142701.0   242543.0         50   \n",
            "3  40.138381              0            0     385000.0        NaN          1   \n",
            "4  37.713668              3            2     353960.0   439378.0         23   \n",
            "\n",
            "    house_id  \n",
            "0  1632918.0  \n",
            "1        NaN  \n",
            "2   681306.0  \n",
            "3        NaN  \n",
            "4  1730985.0  \n",
            "\n",
            "Информация о данных:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11358150 entries, 0 to 11358149\n",
            "Data columns (total 15 columns):\n",
            " #   Column         Dtype  \n",
            "---  ------         -----  \n",
            " 0   date           object \n",
            " 1   price          int64  \n",
            " 2   level          int64  \n",
            " 3   levels         int64  \n",
            " 4   rooms          int64  \n",
            " 5   area           float64\n",
            " 6   kitchen_area   float64\n",
            " 7   geo_lat        float64\n",
            " 8   geo_lon        float64\n",
            " 9   building_type  int64  \n",
            " 10  object_type    int64  \n",
            " 11  postal_code    float64\n",
            " 12  street_id      float64\n",
            " 13  id_region      int64  \n",
            " 14  house_id       float64\n",
            "dtypes: float64(7), int64(7), object(1)\n",
            "memory usage: 1.3+ GB\n",
            "None\n",
            "11358150 7535937\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Просмотр данных \n",
        "print(\"Первые 5 строк данных:\")\n",
        "print(df.head())\n",
        "print(\"\\nИнформация о данных:\")\n",
        "print(df.info())\n",
        "print(df.shape[0],  df[df[\"building_type\"] < 1].shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttEHZ6_FSIxd"
      },
      "source": [
        "Отобразим на карте координаты наших построек."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "G_pSKA2eADcf",
        "outputId": "28f228d6-881e-4b98-f368-27c3699183b8"
      },
      "outputs": [],
      "source": [
        "# Cell 5: Отображение на карте\n",
        "import folium\n",
        "from IPython.display import display\n",
        "\n",
        "map_df = df.head(1000).copy()\n",
        "\n",
        "m = folium.Map(location=[55.751244, 37.618423], zoom_start=10)\n",
        "\n",
        "# Добавляем точки на карту\n",
        "for idx, row in map_df.iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row['geo_lat'], row['geo_lon']],\n",
        "        popup=f\"Price: {row['price']} rub\"\n",
        "    ).add_to(m)\n",
        "\n",
        "#display(m)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gibxhqRJSSr1"
      },
      "source": [
        "# Часть 1. Подготовим данные для обработки моделями машинного обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMAFoSebSdw9"
      },
      "source": [
        "**0.5 Балл**. География наших наблюдений в наборе данных крайне большая. Однако мы знаем, что стоимость квартир в Москве и Санкт-Петербурге намного выше, чем в среднем по России. Давайте сделаем признаки, который показывают, находится ли квартира в 20 килиметрах от центра Москвы или находится ли квартира в 20 килиметрах от центра Санкт-Петербурга.\n",
        "\n",
        "Создайте два признака is_Moscow и is_Saint_Peterburg. Для нахождения расстояния по координатам используйте функцию haversine_distance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pyY7M-9bBDkI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Создание географических признаков...\n",
            "Создано признаков: is_Moscow и is_Saint_Peterburg\n",
            "Квартир в Москве: 1027378\n",
            "Квартир в СПб: 875985\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Функция расчета расстояния Хаверсина и создание признаков\n",
        "def haversine_distance(lat1, lon1, lat2, lon2):\n",
        "    \"\"\"\n",
        "    Расчет расстояния между двумя точками на сфере (Земле) \n",
        "    с использованием формулы Хаверсина\n",
        "    \"\"\"\n",
        "    R = 6371  # Радиус Земли в км\n",
        "    \n",
        "    # Преобразование градусов в радианы\n",
        "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "    \n",
        "    # Разница координат\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    \n",
        "    # Формула Хаверсина\n",
        "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "    \n",
        "    return R * c\n",
        "\n",
        "# Координаты центров городов\n",
        "MOSCOW_CENTER = (55.7558, 37.6173)  # Москва\n",
        "SPB_CENTER = (59.9343, 30.3351)     # Санкт-Петербург\n",
        "\n",
        "print(\"Создание географических признаков...\")\n",
        "\n",
        "# Создаем признаки для Москвы\n",
        "df['distance_to_moscow'] = haversine_distance(\n",
        "    df['geo_lat'], df['geo_lon'], \n",
        "    MOSCOW_CENTER[0], MOSCOW_CENTER[1]\n",
        ")\n",
        "df['is_Moscow'] = df['distance_to_moscow'] <= 20\n",
        "\n",
        "# Создаем признаки для Санкт-Петербурга\n",
        "df['distance_to_spb'] = haversine_distance(\n",
        "    df['geo_lat'], df['geo_lon'],\n",
        "    SPB_CENTER[0], SPB_CENTER[1]\n",
        ")\n",
        "df['is_Saint_Peterburg'] = df['distance_to_spb'] <= 20\n",
        "\n",
        "print(f\"Создано признаков: is_Moscow и is_Saint_Peterburg\")\n",
        "print(f\"Квартир в Москве: {df['is_Moscow'].sum()}\")\n",
        "print(f\"Квартир в СПб: {df['is_Saint_Peterburg'].sum()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uViS3IJQUOd8"
      },
      "source": [
        "**0.5 Балла**. В нашем наборе данных есть признаки, которые мы теоретически можем использовать, например postal_code, но мы это будем делать в рамках домашней работы очень-очень долго. Поэтому предлагается удалить ненужные признаки из датафрейма.\n",
        "\n",
        "Удалим geo_lat,\tgeo_lon,\tobject_type,\tpostal_code,\tstreet_id,\tid_region,\thouse_id."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0wAJaXnlVFJu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Удаляем колонки: ['geo_lat', 'geo_lon', 'object_type', 'postal_code', 'street_id', 'id_region', 'house_id', 'distance_to_moscow', 'distance_to_spb']\n",
            "Оставшиеся колонки: ['date', 'price', 'level', 'levels', 'rooms', 'area', 'kitchen_area', 'building_type', 'is_Moscow', 'is_Saint_Peterburg']\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Удаление ненужных признаков\n",
        "cols_to_drop = ['geo_lat', 'geo_lon', 'object_type', 'postal_code', \n",
        "                'street_id', 'id_region', 'house_id', 'distance_to_moscow', 'distance_to_spb']\n",
        "\n",
        "\n",
        "\n",
        "# Проверяем, какие колонки действительно существуют в данных\n",
        "existing_cols_to_drop = [col for col in cols_to_drop if col in df.columns]\n",
        "print(f\"Удаляем колонки: {existing_cols_to_drop}\")\n",
        "\n",
        "df = df.drop(columns=existing_cols_to_drop)\n",
        "print(f\"Оставшиеся колонки: {df.columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размер после очистки: (11337693, 10)\n"
          ]
        }
      ],
      "source": [
        "# Фильтрация явно аномальных значений\n",
        "def clean_data(df):\n",
        "    # Удаление записей с нулевой или отрицательной площадью\n",
        "    df = df[df['area'] > 10]  # минимальная разумная площадь\n",
        "    \n",
        "    # Удаление записей с нереальными ценами\n",
        "    df = df[(df['price'] > 100000) & (df['price'] < 500000000)]  # разумный диапазон цен\n",
        "    \n",
        "    # Проверка этажности\n",
        "    df = df[df['level'] <= df['levels']]  # этаж не может быть больше общего числа этажей\n",
        "    df = df[df['levels'] > 0]  # должен быть хотя бы 1 этаж\n",
        "    \n",
        "    return df\n",
        "\n",
        "df_clean = clean_data(df.copy())\n",
        "print(f\"Размер после очистки: {df_clean.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6eOYaDCVStV"
      },
      "source": [
        "**0.5 Балл**. Для начала Вам предлагается проанализировать Ваши оставшиеся признаки (колонки) в наборе данных. Какие колонки категориальные? Какие числовые?\n",
        "\n",
        "Категориальные: rooms, building_type, is_Moscow, is_Saint_Petersburg\n",
        "\n",
        "Числовые: price, level, levels, area, kitchen_area\n",
        "\n",
        "Давайте закодируем категориальные признаки с помощью OneHot-Encoding. https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nh9Cf29oWkxw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Анализ типов данных по заданию:\n",
            "date                   object\n",
            "price                   int64\n",
            "level                   int64\n",
            "levels                  int64\n",
            "rooms                   int64\n",
            "area                  float64\n",
            "kitchen_area          float64\n",
            "building_type           int64\n",
            "is_Moscow                bool\n",
            "is_Saint_Peterburg       bool\n",
            "dtype: object\n",
            "Числовой: date\n",
            "Числовой: level\n",
            "Числовой: levels\n",
            "Числовой: rooms\n",
            "Числовой: area\n",
            "Числовой: kitchen_area\n",
            "Категориальный: building_type - 7 уникальных значений\n",
            "Числовой: is_Moscow\n",
            "Числовой: is_Saint_Peterburg\n",
            "\n",
            "ИТОГО:\n",
            "Категориальные признаки для кодирования: ['building_type']\n",
            "Числовые признаки: ['date', 'level', 'levels', 'rooms', 'area', 'kitchen_area', 'is_Moscow', 'is_Saint_Peterburg']\n",
            "\n",
            "Применяем One-Hot Encoding к: ['building_type']\n",
            "После кодирования. Размер: (11358150, 15)\n",
            "Новые колонки от OneHotEncoder: ['building_type_1', 'building_type_2', 'building_type_3', 'building_type_4', 'building_type_5', 'building_type_6']\n",
            "\n",
            "Итоговые колонки: ['date', 'price', 'level', 'levels', 'rooms', 'area', 'kitchen_area', 'is_Moscow', 'is_Saint_Peterburg', 'building_type_1', 'building_type_2', 'building_type_3', 'building_type_4', 'building_type_5', 'building_type_6']\n"
          ]
        }
      ],
      "source": [
        "# Выводим заголовок для наглядности — начинаем анализ типов данных в датафрейме\n",
        "print(\"Анализ типов данных по заданию:\")\n",
        "# Выводим типы данных всех столбцов в датафрейме df (например, int64, object, float64 и т.д.)\n",
        "print(df.dtypes)\n",
        "\n",
        "# Инициализируем два пустых списка для хранения имён категориальных и числовых признаков\n",
        "categorical_cols = []   # Список для категориальных признаков\n",
        "numerical_cols = []     # Список для числовых признаков\n",
        "\n",
        "# Проходим по всем столбцам датафрейма\n",
        "for col in df.columns:\n",
        "    # Пропускаем целевую переменную 'price', так как она не используется как признак\n",
        "    if col == 'price':\n",
        "        continue\n",
        "    # Согласно заданию, 'building_type' — единственный явно указанный категориальный признак\n",
        "    elif col == 'building_type':\n",
        "        categorical_cols.append(col)  # Добавляем его в список категориальных\n",
        "        # Выводим информацию: имя признака и количество уникальных значений (для понимания разнообразия категорий)\n",
        "        print(f\"Категориальный: {col} - {df[col].nunique()} уникальных значений\")\n",
        "    else:\n",
        "        # Все остальные признаки (кроме 'price' и 'building_type') считаем числовыми\n",
        "        numerical_cols.append(col)\n",
        "        print(f\"Числовой: {col}\")\n",
        "\n",
        "# Выводим итоговую сводку по типам признаков\n",
        "print(f\"\\nИТОГО:\")\n",
        "print(f\"Категориальные признаки для кодирования: {categorical_cols}\")\n",
        "print(f\"Числовые признаки: {numerical_cols}\")\n",
        "\n",
        "# Проверяем, есть ли категориальные признаки, требующие кодирования\n",
        "if categorical_cols:\n",
        "    print(f\"\\nПрименяем One-Hot Encoding к: {categorical_cols}\")\n",
        "    \n",
        "    # Создаём экземпляр OneHotEncoder из sklearn\n",
        "    # drop='first' — удаляем один из фиктивных признаков, чтобы избежать мультиколлинеарности (ловушки фиктивной переменной)\n",
        "    # sparse_output=False — возвращаем плотный массив (DataFrame), а не разреженную матрицу\n",
        "    encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
        "    \n",
        "    # Применяем обучение и трансформацию только к столбцам из categorical_cols (в данном случае — только 'building_type')\n",
        "    encoded_cols = encoder.fit_transform(df[categorical_cols])\n",
        "    \n",
        "    # Преобразуем результат в pandas DataFrame с осмысленными названиями столбцов\n",
        "    # encoder.get_feature_names_out(categorical_cols) генерирует имена новых бинарных признаков,\n",
        "    # например: 'building_type_1', 'building_type_2' и т.д.\n",
        "    encoded_df = pd.DataFrame(\n",
        "        encoded_cols, \n",
        "        columns=encoder.get_feature_names_out(categorical_cols)\n",
        "    )\n",
        "    \n",
        "    # Удаляем исходные категориальные столбцы из df и добавляем новые закодированные столбцы\n",
        "    # axis=1 означает объединение по столбцам (горизонтально)\n",
        "    df = pd.concat([df.drop(columns=categorical_cols), encoded_df], axis=1)\n",
        "    \n",
        "    # Выводим информацию о результатах кодирования\n",
        "    print(f\"После кодирования. Размер: {df.shape}\")  # Новый размер датафрейма\n",
        "    # Показываем, какие новые столбцы \n",
        "    print(f\"Новые колонки от OneHotEncoder: {[col for col in df.columns if 'building_type' in col]}\")\n",
        "else:\n",
        "    # Если категориальных признаков нет, выводим \n",
        "    print(\"Нет категориальных признаков для кодирования\")\n",
        "\n",
        "# Выводим полный список колонок в итоговом датафрейме\n",
        "print(f\"\\nИтоговые колонки: {df.columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN3XDyceWtYw"
      },
      "source": [
        "**0.5 Балл**. Поработаем с числовыми признаками:\n",
        "\n",
        "\n",
        "1.   Добавьте в ваш датасет два признака: количество дней со дня первого наблюдения (разница между датами объявлений). Возможно, для предсказания цены не так важен этаж, как важно отношение этажа квартиры на количество этажей в доме, добавьте этот признак. После добавления нового признака колонку date можно удалить.\n",
        "2.   Числовые признаки могут иметь разные порядки. Давайте отнормируем числовые признаки с помощью StandartScaller https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YcTeaYNnX7o7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Работа с числовыми признаками по заданию...\n",
            "1. Обрабатываем колонку 'date'...\n",
            "Создан признак 'days_from_first'. Удалена колонка 'date'\n",
            "Данные после обработки даты:\n",
            "      price  level  levels  rooms  area  kitchen_area  is_Moscow  \\\n",
            "0   2451300     15      31      1  30.3           0.0      False   \n",
            "1   1450000      5       5      1  33.0           6.0      False   \n",
            "2  10700000      4      13      3  85.0          12.0      False   \n",
            "3   3100000      3       5      3  82.0           9.0      False   \n",
            "4   2500000      2       3      1  30.0           9.0      False   \n",
            "\n",
            "   is_Saint_Peterburg  building_type_1  building_type_2  building_type_3  \\\n",
            "0               False              0.0              0.0              0.0   \n",
            "1               False              0.0              0.0              0.0   \n",
            "2               False              0.0              0.0              1.0   \n",
            "3               False              0.0              0.0              0.0   \n",
            "4               False              0.0              0.0              1.0   \n",
            "\n",
            "   building_type_4  building_type_5  building_type_6  days_from_first  \n",
            "0              0.0              0.0              0.0                0  \n",
            "1              0.0              0.0              0.0                0  \n",
            "2              0.0              0.0              0.0                0  \n",
            "3              0.0              0.0              0.0                0  \n",
            "4              0.0              0.0              0.0                0  \n",
            "\n",
            "2. Создаем признак 'level_ratio'...\n",
            "Создан признак 'level_ratio'\n",
            "Колонки 'level' и 'levels' удалены\n",
            "Данные после создания level_ratio:\n",
            "      price  rooms  area  kitchen_area  is_Moscow  is_Saint_Peterburg  \\\n",
            "0   2451300      1  30.3           0.0      False               False   \n",
            "1   1450000      1  33.0           6.0      False               False   \n",
            "2  10700000      3  85.0          12.0      False               False   \n",
            "3   3100000      3  82.0           9.0      False               False   \n",
            "4   2500000      1  30.0           9.0      False               False   \n",
            "\n",
            "   building_type_1  building_type_2  building_type_3  building_type_4  \\\n",
            "0              0.0              0.0              0.0              0.0   \n",
            "1              0.0              0.0              0.0              0.0   \n",
            "2              0.0              0.0              1.0              0.0   \n",
            "3              0.0              0.0              0.0              0.0   \n",
            "4              0.0              0.0              1.0              0.0   \n",
            "\n",
            "   building_type_5  building_type_6  days_from_first  level_ratio  \n",
            "0              0.0              0.0                0     0.483871  \n",
            "1              0.0              0.0                0     1.000000  \n",
            "2              0.0              0.0                0     0.307692  \n",
            "3              0.0              0.0                0     0.600000  \n",
            "4              0.0              0.0                0     0.666667  \n",
            "\n",
            "3. Подготовка данных для моделирования...\n",
            "Числовые признаки для нормализации: ['rooms', 'area', 'kitchen_area', 'days_from_first', 'level_ratio']\n",
            "Размерность признаков: (11358150, 13)\n",
            "Размерность целевой переменной: (11358150,)\n",
            "Обучающая выборка: (9086520, 13)\n",
            "Тестовая выборка: (2271630, 13)\n",
            "\n",
            "4. Нормализация числовых признаков...\n",
            "Нормализация завершена!\n",
            "Статистика после нормализации:\n",
            "  rooms: mean=-0.00, std=1.00\n",
            "  area: mean=-0.00, std=1.00\n",
            "  kitchen_area: mean=-0.00, std=1.00\n",
            "\n",
            "Итоговый размер обучающих данных: (9086520, 13)\n",
            "Итоговый размер тестовых данных: (2271630, 13)\n",
            "Итоговые колонки: ['rooms', 'area', 'kitchen_area', 'is_Moscow', 'is_Saint_Peterburg', 'building_type_1', 'building_type_2', 'building_type_3', 'building_type_4', 'building_type_5', 'building_type_6', 'days_from_first', 'level_ratio']\n",
            "\n",
            "Первые 5 строк обучающих данных после обработки:\n",
            "             rooms      area  kitchen_area  is_Moscow  is_Saint_Peterburg  \\\n",
            "11286448  0.242330  0.180673      0.764136       True               False   \n",
            "4359929   0.242330 -0.365415      0.082519      False               False   \n",
            "10764986  0.242330 -0.114510      0.267574      False               False   \n",
            "5689715   0.242330 -0.793431      0.082519      False               False   \n",
            "2608085  -0.621663 -0.645839      0.329258      False               False   \n",
            "\n",
            "          building_type_1  building_type_2  building_type_3  building_type_4  \\\n",
            "11286448              0.0              0.0              0.0              0.0   \n",
            "4359929               0.0              0.0              0.0              0.0   \n",
            "10764986              0.0              0.0              0.0              0.0   \n",
            "5689715               0.0              0.0              0.0              0.0   \n",
            "2608085               0.0              0.0              0.0              1.0   \n",
            "\n",
            "          building_type_5  building_type_6  days_from_first  level_ratio  \n",
            "11286448              0.0              0.0         1.713158    -0.609955  \n",
            "4359929               0.0              0.0        -0.379946     1.452729  \n",
            "10764986              0.0              0.0         1.524680    -1.276361  \n",
            "5689715               0.0              0.0         0.026771    -0.537232  \n",
            "2608085               0.0              0.0        -0.955302    -1.276361  \n"
          ]
        }
      ],
      "source": [
        "# Cell 9: Работа с числовыми признаками (исправленная версия)\n",
        "print(\"Работа с числовыми признаками по заданию...\")\n",
        "\n",
        "# 1. Обработка даты согласно заданию (если колонка существует)\n",
        "if 'date' in df.columns:\n",
        "    print(\"1. Обрабатываем колонку 'date'...\")\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    first_date = df['date'].min()\n",
        "    df['days_from_first'] = (df['date'] - first_date).dt.days\n",
        "    df = df.drop(columns=['date'])\n",
        "    print(f\"Создан признак 'days_from_first'. Удалена колонка 'date'\")\n",
        "else:\n",
        "    print(\"1. Колонка 'date' не найдена, пропускаем этот шаг\")\n",
        "\n",
        "print(\"Данные после обработки даты:\")\n",
        "print(df.head())\n",
        "\n",
        "# 2. Создаем признак отношения этажа согласно заданию\n",
        "print(\"\\n2. Создаем признак 'level_ratio'...\")\n",
        "# Проверяем наличие необходимых колонок и обрабатываем возможные ошибки\n",
        "if 'level' in df.columns and 'levels' in df.columns:\n",
        "    # Защита от деления на ноль\n",
        "    df['level_ratio'] = np.where(df['levels'] != 0, df['level'] / df['levels'], 0)\n",
        "    print(f\"Создан признак 'level_ratio'\")\n",
        "    to_drop = ['level', 'levels']\n",
        "    df = df.drop(columns=to_drop)\n",
        "    print(\"Колонки 'level' и 'levels' удалены\")\n",
        "else:\n",
        "    missing_cols = []\n",
        "    if 'level' not in df.columns:\n",
        "        missing_cols.append('level')\n",
        "    if 'levels' not in df.columns:\n",
        "        missing_cols.append('levels')\n",
        "    print(f\"   Предупреждение: колонки {missing_cols} не найдены\")\n",
        "\n",
        "print(\"Данные после создания level_ratio:\")\n",
        "print(df.head())\n",
        "\n",
        "# 3. Подготовка данных для моделирования\n",
        "print(\"\\n3. Подготовка данных для моделирования...\")\n",
        "\n",
        "# Определяем числовые признаки для нормализации (все кроме price)\n",
        "# Исключаем также бинарные признаки is_Moscow и is_Saint_Peterburg\n",
        "numerical_features_to_scale = [col for col in df.columns \n",
        "                              if col != 'price' and \n",
        "                              df[col].dtype in ['int64', 'float64', 'int32'] and\n",
        "                              'building_type' not in col and\n",
        "                              col not in ['is_Moscow', 'is_Saint_Peterburg']]\n",
        "\n",
        "print(f\"Числовые признаки для нормализации: {numerical_features_to_scale}\")\n",
        "\n",
        "# Разделение на признаки и целевую переменную\n",
        "X = df.drop(columns=['price'])\n",
        "y = df['price']\n",
        "\n",
        "print(f\"Размерность признаков: {X.shape}\")\n",
        "print(f\"Размерность целевой переменной: {y.shape}\")\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=28)\n",
        "\n",
        "print(f\"Обучающая выборка: {X_train.shape}\")\n",
        "print(f\"Тестовая выборка: {X_test.shape}\")\n",
        "\n",
        "# 4. Нормализация числовых признаков\n",
        "print(\"\\n4. Нормализация числовых признаков...\")\n",
        "\n",
        "if numerical_features_to_scale:\n",
        "    # Применяем StandardScaler отдельно к train и test\n",
        "    scaler = StandardScaler()\n",
        "    \n",
        "    # Обучаем scaler на train данных и преобразуем train\n",
        "    X_train[numerical_features_to_scale] = scaler.fit_transform(X_train[numerical_features_to_scale])\n",
        "    \n",
        "    # Преобразуем test на основе параметров из train\n",
        "    X_test[numerical_features_to_scale] = scaler.transform(X_test[numerical_features_to_scale])\n",
        "    \n",
        "    print(\"Нормализация завершена!\")\n",
        "    print(\"Статистика после нормализации:\")\n",
        "    for col in numerical_features_to_scale[:3]:  # Показываем только первые 3 признака\n",
        "        print(f\"  {col}: mean={X_train[col].mean():.2f}, std={X_train[col].std():.2f}\")\n",
        "else:\n",
        "    print(\"   Нет числовых признаков для нормализации\")\n",
        "\n",
        "print(f\"\\nИтоговый размер обучающих данных: {X_train.shape}\")\n",
        "print(f\"Итоговый размер тестовых данных: {X_test.shape}\")\n",
        "print(f\"Итоговые колонки: {X_train.columns.tolist()}\")\n",
        "\n",
        "# Показываем итоговые данные\n",
        "print(\"\\nПервые 5 строк обучающих данных после обработки:\")\n",
        "print(X_train.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrYv0DFtX88C"
      },
      "source": [
        "**2 Балла**. Реализуйте класс KNNRegressor, который должен делать регрессию методом k ближайших соседей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "awcnGJ9HNLRx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numba import njit, prange\n",
        "\n",
        "@njit(parallel=True, fastmath=True)\n",
        "def euclidean_distances(X1, X2):\n",
        "    n1, n2 = X1.shape[0], X2.shape[0]\n",
        "    D = np.empty((n1, n2), dtype=np.float32)\n",
        "    for i in prange(n1):\n",
        "        for j in range(n2):\n",
        "            s = 0.0\n",
        "            for k in range(X1.shape[1]):\n",
        "                diff = X1[i, k] - X2[j, k]\n",
        "                s += diff * diff\n",
        "            D[i, j] = np.sqrt(s)\n",
        "    return D\n",
        "\n",
        "\n",
        "class KNNRegressor:\n",
        "    def __init__(self, n_neighbors=5, batch_size=5000):\n",
        "        self.k = n_neighbors\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Преобразуем DataFrame → NumPy float32\n",
        "        if not isinstance(X, np.ndarray):\n",
        "            X = X.to_numpy(dtype=np.float32)\n",
        "        if not isinstance(y, np.ndarray):\n",
        "            y = y.to_numpy(dtype=np.float32)\n",
        "\n",
        "        self.X_train = X.astype(np.float32)\n",
        "        self.y_train = y.astype(np.float32)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Преобразуем DataFrame → NumPy float32\n",
        "        if not isinstance(X, np.ndarray):\n",
        "            X = X.to_numpy(dtype=np.float32)\n",
        "        X = X.astype(np.float32)\n",
        "\n",
        "        n_test = X.shape[0]\n",
        "        y_pred = np.zeros(n_test, dtype=np.float32)\n",
        "\n",
        "        for start in range(0, n_test, self.batch_size):\n",
        "            end = min(start + self.batch_size, n_test)\n",
        "            X_batch = X[start:end]\n",
        "\n",
        "            dists = euclidean_distances(X_batch, self.X_train)\n",
        "\n",
        "            # Быстрая частичная сортировка по k\n",
        "            idx = np.argpartition(dists, self.k, axis=1)[:, :self.k]\n",
        "            y_pred[start:end] = np.mean(self.y_train[idx], axis=1)\n",
        "\n",
        "        return y_pred\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN3nHVC4ZXk_"
      },
      "source": [
        "**3 Балла**. Реализуйте класс LinearRegression, поддерживающий обучение градиентными спусками SGD, Momentum, AdaGrad. Используйте градиент для оптимизации функции потерь MSE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OYSbuTWGN4t2"
      },
      "outputs": [],
      "source": [
        "class LinearRegression:\n",
        "    def __init__(self, learning_rate=0.01, optimization='SGD', max_iter=1000, tolerance=1e-4):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.optimization = optimization\n",
        "        self.max_iter = max_iter\n",
        "        self.tolerance = tolerance\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.loss_history = []\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        #Нормализация входных данных\n",
        "        X = X.values if isinstance(X, pd.DataFrame) else X\n",
        "        y = y.values if isinstance(y, pd.Series) else y\n",
        "        \n",
        "        # Нормализация признаков\n",
        "        self.X_mean = np.mean(X, axis=0)\n",
        "        self.X_std = np.std(X, axis=0) + 1e-8\n",
        "        X_normalized = (X - self.X_mean) / self.X_std\n",
        "        \n",
        "        # Нормализация целевой переменной\n",
        "        self.y_mean = np.mean(y)\n",
        "        self.y_std = np.std(y) + 1e-8\n",
        "        y_normalized = (y - self.y_mean) / self.y_std\n",
        "        \n",
        "        n_samples, n_features = X_normalized.shape\n",
        "        \n",
        "        # Стабильная инициализация\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0.0\n",
        "        \n",
        "        # Инициализация для оптимизаторов\n",
        "        if self.optimization == 'Momentum':\n",
        "            self.v_w = np.zeros(n_features)\n",
        "            self.v_b = 0.0\n",
        "        elif self.optimization == 'AdaGrad':\n",
        "            self.s_w = np.zeros(n_features) + 1e-8\n",
        "            self.s_b = 1e-8\n",
        "        \n",
        "        previous_loss = float('inf')\n",
        "        \n",
        "        for iteration in range(self.max_iter):\n",
        "            # Прямое распространение\n",
        "            y_pred = np.dot(X_normalized, self.weights) + self.bias\n",
        "            \n",
        "            # Градиенты без регуляризации для стабильности\n",
        "            error = y_pred - y_normalized\n",
        "            dw = np.dot(X_normalized.T, error) / n_samples\n",
        "            db = np.sum(error) / n_samples\n",
        "            \n",
        "            # Клиппинг градиентов\n",
        "            dw = np.clip(dw, -1.0, 1.0)\n",
        "            db = np.clip(db, -1.0, 1.0)\n",
        "            \n",
        "            # Обновление параметров\n",
        "            current_lr = self.learning_rate / (1 + 0.001 * iteration)  # decay\n",
        "            \n",
        "            if self.optimization == 'SGD':\n",
        "                self.weights -= current_lr * dw\n",
        "                self.bias -= current_lr * db\n",
        "            elif self.optimization == 'Momentum':\n",
        "                self.v_w = 0.9 * self.v_w + current_lr * dw\n",
        "                self.v_b = 0.9 * self.v_b + current_lr * db\n",
        "                self.weights -= self.v_w\n",
        "                self.bias -= self.v_b\n",
        "            elif self.optimization == 'AdaGrad':\n",
        "                self.s_w += dw**2\n",
        "                self.s_b += db**2\n",
        "                self.weights -= current_lr * dw / np.sqrt(self.s_w)\n",
        "                self.bias -= current_lr * db / np.sqrt(self.s_b)\n",
        "            \n",
        "            # Loss\n",
        "            loss = np.mean(error**2)\n",
        "            self.loss_history.append(loss)\n",
        "            \n",
        "            if abs(previous_loss - loss) < self.tolerance:\n",
        "                break\n",
        "            previous_loss = loss\n",
        "    \n",
        "    def predict(self, X):\n",
        "        X = X.values if isinstance(X, pd.DataFrame) else X\n",
        "        X_normalized = (X - self.X_mean) / self.X_std\n",
        "        y_pred_normalized = np.dot(X_normalized, self.weights) + self.bias\n",
        "        # Денормализация предсказаний\n",
        "        return y_pred_normalized * self.y_std + self.y_mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITiFeRiITepF"
      },
      "source": [
        "# Часть 2. Эксперименты с моделями машинного обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjqg8pb1bSLB"
      },
      "source": [
        "**3 Балла**. Проведите эксперименты с написанными Вами методами машинного обучения. Выделите обучающую и тестовую выборки в отношении 0,8 и 0,2 соответственно. Измерьте ошибку MSE, MAE, RMSE. Заиспользуйте методы KNNRegressor и LinearRegression из библиотеки sklearn, сравните качество Ваших решений и библиотечных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Нормализация целевой переменной\n",
        "y_train_log = np.log1p(y_train)\n",
        "y_test_log = np.log1p(y_test)\n",
        "\n",
        "# 2. Улучшенная обработка выбросов\n",
        "def improved_clean_data(df):\n",
        "    df = df.copy()\n",
        "    \n",
        "    # Агрессивная фильтрация выбросов\n",
        "    df = df[df['area'].between(20, 200)]  # разумные пределы площади\n",
        "    df = df[df['price'].between(500000, 50000000)]  # разумные пределы цены\n",
        "    df = df[df['kitchen_area'] <= df['area']]  # кухня не больше всей площади\n",
        "    df = df[df['level'] <= df['levels']]  # этаж не больше общего числа этажей\n",
        "    df = df[df['levels'] <= 50]  # разумное количество этажей в доме\n",
        "    \n",
        "    # Обработка аномальных значений комнат\n",
        "    df = df[df['rooms'].between(-1, 10)]\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ww7RbR2ZcG8H"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ФИНАЛЬНЫЕ ЭКСПЕРИМЕНТЫ С ИСПРАВЛЕННЫМИ МОДЕЛЯМИ ===\n",
            "\n",
            "Размер после очистки: (90283, 12)\n",
            "Числовые колонки: ['rooms', 'area', 'kitchen_area', 'building_type_1', 'building_type_2', 'building_type_3', 'building_type_4', 'building_type_5', 'building_type_6', 'days_from_first', 'level_ratio']\n",
            "Размер обучающей выборки: (70283, 11)\n",
            "Размер тестовой выборки: (20000, 11)\n",
            "Диапазон цен: 1,500,000 - 12,052,490\n",
            "\n",
            "1. Обучение нашей LinearRegression (SGD)...\n",
            "Our LR (SGD) - MSE: 4238757739365.64, MAE: 1540112.07, RMSE: 2058824.36, MAPE: 40.5%\n",
            "   ✅ Успешно. Final loss: 0.7525\n",
            "\n",
            "2. Обучение нашей LinearRegression (Momentum)...\n",
            "Our LR (Momentum) - MSE: 4230729459134.44, MAE: 1537523.66, RMSE: 2056873.71, MAPE: 40.5%\n",
            "   ✅ Успешно. Final loss: 0.7516\n",
            "\n",
            "3. Обучение нашей LinearRegression (AdaGrad)...\n",
            "Our LR (AdaGrad) - MSE: 4234560384309.79, MAE: 1539279.06, RMSE: 2057804.75, MAPE: 40.5%\n",
            "   ✅ Успешно. Final loss: 0.7519\n",
            "\n",
            "4. Обучение библиотечного LinearRegression...\n",
            "Sklearn LR - MSE: 4227969096457.33, MAE: 1536134.04, RMSE: 2056202.59, MAPE: 40.3%\n",
            "   ✅ Успешно\n",
            "\n",
            "5. Обучение нашего KNNRegressor...\n",
            "Our KNN - MSE: 4531960506627.93, MAE: 1509302.97, RMSE: 2128840.18, MAPE: 39.5%\n",
            "   ✅ Успешно\n",
            "\n",
            "6. Обучение библиотечного KNeighborsRegressor...\n",
            "Sklearn KNN - MSE: 4163658545754.46, MAE: 1466969.88, RMSE: 2040504.48, MAPE: 38.4%\n",
            "   ✅ Успешно\n",
            "\n",
            "================================================================================\n",
            "ФИНАЛЬНЫЕ РЕЗУЛЬТАТЫ:\n",
            "================================================================================\n",
            "                   Model   MSE   MAE  RMSE  MAPE\n",
            "            Our LR (SGD) 4.24T 1.54M 2.06M 40.5%\n",
            "       Our LR (Momentum) 4.23T 1.54M 2.06M 40.5%\n",
            "        Our LR (AdaGrad) 4.23T 1.54M 2.06M 40.5%\n",
            "Sklearn LinearRegression 4.23T 1.54M 2.06M 40.3%\n",
            "                 Our KNN 4.53T 1.51M 2.13M 39.5%\n",
            "             Sklearn KNN 4.16T 1.47M 2.04M 38.4%\n",
            "\n",
            "🏆 Лучшая модель: Sklearn KNN (MSE: 4.16T)\n",
            "✅ Наши рабочие модели: Our LR (SGD), Our LR (Momentum), Our LR (AdaGrad), Our KNN\n",
            "✅ Библиотечные модели: Sklearn LinearRegression, Sklearn KNN\n"
          ]
        }
      ],
      "source": [
        "def run_final_experiments():\n",
        "    print(\"=== ФИНАЛЬНЫЕ ЭКСПЕРИМЕНТЫ С ИСПРАВЛЕННЫМИ МОДЕЛЯМИ ===\\n\")\n",
        "    \n",
        "    # Используем меньшую выборку для стабильности\n",
        "    sample_size = 100000\n",
        "    test_size = 20000\n",
        "    \n",
        "    # Строгая очистка данных\n",
        "    def strict_clean_data(df):\n",
        "        df = df.copy()\n",
        "        # Убедимся, что все колонки числовые\n",
        "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "        df = df[numeric_cols]\n",
        "        \n",
        "        # Фильтрация выбросов\n",
        "        df = df[df['area'].between(25, 150)]\n",
        "        df = df[df['price'].between(1000000, 20000000)]\n",
        "        if 'kitchen_area' in df.columns:\n",
        "            df = df[df['kitchen_area'].between(5, 50)]\n",
        "        if 'level_ratio' in df.columns:\n",
        "            df = df[df['level_ratio'].between(0.05, 0.95)]\n",
        "        if 'rooms' in df.columns:\n",
        "            df = df[df['rooms'].between(1, 5)]\n",
        "        if 'days_from_first' in df.columns:\n",
        "            df = df[df['days_from_first'].between(0, 1000)]\n",
        "\n",
        "\n",
        "        df = df[:100000]\n",
        "\n",
        "        target = \"price\"\n",
        "        features = [c for c in df.columns if c != target]\n",
        "\n",
        "        # Убираем выбросы\n",
        "        q_low, q_high = df[target].quantile([0.05, 0.95])\n",
        "        df = df[(df[target] >= q_low) & (df[target] <= q_high)]\n",
        "\n",
        "        \n",
        "        return df\n",
        "    \n",
        "\n",
        "    # Применяем очистку\n",
        "    df_strict = strict_clean_data(df)\n",
        "    print(f\"Размер после очистки: {df_strict.shape}\")\n",
        "    \n",
        "    \n",
        "    \n",
        "    # Подготовка данных\n",
        "    X_final = df_strict.drop(columns=['price'])\n",
        "    y_final = df_strict['price']\n",
        "    \n",
        "    # Убедимся, что все признаки числовые\n",
        "    X_final = X_final.select_dtypes(include=[np.number])\n",
        "    \n",
        "    print(f\"Числовые колонки: {X_final.columns.tolist()}\")\n",
        "    \n",
        "    # Подвыборка\n",
        "    sample_indices = np.random.choice(len(X_final), size=min(sample_size + test_size, len(X_final)), replace=False)\n",
        "    X_sample = X_final.iloc[sample_indices]\n",
        "    y_sample = y_final.iloc[sample_indices]\n",
        "    \n",
        "    X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
        "        X_sample, y_sample, test_size=test_size, random_state=42\n",
        "    )\n",
        "    \n",
        "    print(f\"Размер обучающей выборки: {X_train_final.shape}\")\n",
        "    print(f\"Размер тестовой выборки: {X_test_final.shape}\")\n",
        "    print(f\"Диапазон цен: {y_train_final.min():,.0f} - {y_train_final.max():,.0f}\\n\")\n",
        "    \n",
        "    def safe_metrics(y_true, y_pred, model_name):\n",
        "        \"\"\"Безопасное вычисление метрик\"\"\"\n",
        "        y_true = np.array(y_true, dtype=np.float64)\n",
        "        y_pred = np.array(y_pred, dtype=np.float64)\n",
        "        \n",
        "        # Защита от аномальных значений\n",
        "        y_pred = np.nan_to_num(y_pred, nan=np.mean(y_true))\n",
        "        y_pred = np.clip(y_pred, y_true.min() * 0.1, y_true.max() * 10)\n",
        "        \n",
        "        mse = mean_squared_error(y_true, y_pred)\n",
        "        mae = mean_absolute_error(y_true, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        \n",
        "        # MAPE\n",
        "        mask = (y_true != 0) & (np.abs(y_true) > 1000)\n",
        "        if np.sum(mask) > len(y_true) * 0.5:\n",
        "            mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
        "        else:\n",
        "            mape = np.inf\n",
        "        \n",
        "        print(f\"{model_name} - MSE: {mse:.2f}, MAE: {mae:.2f}, RMSE: {rmse:.2f}, MAPE: {mape:.1f}%\")\n",
        "        return [mse, mae, rmse, mape]\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    # 1. Наша LinearRegression (SGD)\n",
        "    print(\"1. Обучение нашей LinearRegression (SGD)...\")\n",
        "    try:\n",
        "        lr_sgd = LinearRegression(learning_rate=0.1, optimization='SGD', max_iter=300, tolerance=1e-4)\n",
        "        lr_sgd.fit(X_train_final, y_train_final)\n",
        "        y_pred_sgd = lr_sgd.predict(X_test_final)\n",
        "        \n",
        "        metrics_sgd = safe_metrics(y_test_final, y_pred_sgd, \"Our LR (SGD)\")\n",
        "        results.append([\"Our LR (SGD)\"] + metrics_sgd)\n",
        "        print(f\"   ✅ Успешно. Final loss: {lr_sgd.loss_history[-1]:.4f}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ Ошибка: {e}\")\n",
        "        results.append([\"Our LR (SGD)\", np.inf, np.inf, np.inf, np.inf])\n",
        "    \n",
        "    # 2. Наша LinearRegression (Momentum)\n",
        "    print(\"2. Обучение нашей LinearRegression (Momentum)...\")\n",
        "    try:\n",
        "        lr_momentum = LinearRegression(learning_rate=0.1, optimization='Momentum', max_iter=300, tolerance=1e-4)\n",
        "        lr_momentum.fit(X_train_final, y_train_final)\n",
        "        y_pred_momentum = lr_momentum.predict(X_test_final)\n",
        "        \n",
        "        metrics_momentum = safe_metrics(y_test_final, y_pred_momentum, \"Our LR (Momentum)\")\n",
        "        results.append([\"Our LR (Momentum)\"] + metrics_momentum)\n",
        "        print(f\"   ✅ Успешно. Final loss: {lr_momentum.loss_history[-1]:.4f}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ Ошибка: {e}\")\n",
        "        results.append([\"Our LR (Momentum)\", np.inf, np.inf, np.inf, np.inf])\n",
        "    \n",
        "    # 3. Наша LinearRegression (AdaGrad)\n",
        "    print(\"3. Обучение нашей LinearRegression (AdaGrad)...\")\n",
        "    try:\n",
        "        lr_adagrad = LinearRegression(learning_rate=0.1, optimization='AdaGrad', max_iter=300, tolerance=1e-4)\n",
        "        lr_adagrad.fit(X_train_final, y_train_final)\n",
        "        y_pred_adagrad = lr_adagrad.predict(X_test_final)\n",
        "        \n",
        "        metrics_adagrad = safe_metrics(y_test_final, y_pred_adagrad, \"Our LR (AdaGrad)\")\n",
        "        results.append([\"Our LR (AdaGrad)\"] + metrics_adagrad)\n",
        "        print(f\"   ✅ Успешно. Final loss: {lr_adagrad.loss_history[-1]:.4f}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ Ошибка: {e}\")\n",
        "        results.append([\"Our LR (AdaGrad)\", np.inf, np.inf, np.inf, np.inf])\n",
        "    \n",
        "    # 4. Библиотечный LinearRegression\n",
        "    print(\"4. Обучение библиотечного LinearRegression...\")\n",
        "    try:\n",
        "        lr_sklearn = SkLinearRegression()\n",
        "        lr_sklearn.fit(X_train_final, y_train_final)\n",
        "        y_pred_sklearn = lr_sklearn.predict(X_test_final)\n",
        "        \n",
        "        metrics_sklearn = safe_metrics(y_test_final, y_pred_sklearn, \"Sklearn LR\")\n",
        "        results.append([\"Sklearn LinearRegression\"] + metrics_sklearn)\n",
        "        print(\"   ✅ Успешно\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ Ошибка: {e}\")\n",
        "        results.append([\"Sklearn LinearRegression\", np.inf, np.inf, np.inf, np.inf])\n",
        "    \n",
        "    # 5. Наш KNNRegressor\n",
        "    print(\"5. Обучение нашего KNNRegressor...\")\n",
        "    try:\n",
        "        knn_our = KNNRegressor(n_neighbors=3)\n",
        "        knn_our.fit(X_train_final, y_train_final)\n",
        "        y_pred_knn = knn_our.predict(X_test_final)\n",
        "        \n",
        "        metrics_knn = safe_metrics(y_test_final, y_pred_knn, \"Our KNN\")\n",
        "        results.append([\"Our KNN\"] + metrics_knn)\n",
        "        print(\"   ✅ Успешно\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ Ошибка: {e}\")\n",
        "        results.append([\"Our KNN\", np.inf, np.inf, np.inf, np.inf])\n",
        "    \n",
        "    # 6. Библиотечный KNN\n",
        "    print(\"6. Обучение библиотечного KNeighborsRegressor...\")\n",
        "    try:\n",
        "        knn_sklearn = KNeighborsRegressor(n_neighbors=5)\n",
        "        knn_sklearn.fit(X_train_final, y_train_final)\n",
        "        y_pred_sklearn_knn = knn_sklearn.predict(X_test_final)\n",
        "        \n",
        "        metrics_sklearn_knn = safe_metrics(y_test_final, y_pred_sklearn_knn, \"Sklearn KNN\")\n",
        "        results.append([\"Sklearn KNN\"] + metrics_sklearn_knn)\n",
        "        print(\"   ✅ Успешно\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ Ошибка: {e}\")\n",
        "        results.append([\"Sklearn KNN\", np.inf, np.inf, np.inf, np.inf])\n",
        "    \n",
        "    # Вывод результатов\n",
        "    print(\"=\"*80)\n",
        "    print(\"ФИНАЛЬНЫЕ РЕЗУЛЬТАТЫ:\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    results_df = pd.DataFrame(results, columns=[\"Model\", \"MSE\", \"MAE\", \"RMSE\", \"MAPE\"])\n",
        "    \n",
        "    def format_metric(x):\n",
        "        if x == np.inf: \n",
        "            return \"FAILED\"\n",
        "        elif x > 1e12: \n",
        "            return f\"{x/1e12:.2f}T\"\n",
        "        elif x > 1e9: \n",
        "            return f\"{x/1e9:.2f}B\"\n",
        "        elif x > 1e6: \n",
        "            return f\"{x/1e6:.2f}M\"\n",
        "        elif x > 1e3: \n",
        "            return f\"{x/1e3:.2f}K\"\n",
        "        else: \n",
        "            return f\"{x:.2f}\"\n",
        "    \n",
        "    display_df = results_df.copy()\n",
        "    for col in ['MSE', 'MAE', 'RMSE']:\n",
        "        display_df[col] = display_df[col].apply(format_metric)\n",
        "    display_df['MAPE'] = results_df['MAPE'].apply(lambda x: f\"{x:.1f}%\" if x != np.inf else \"FAILED\")\n",
        "    \n",
        "    print(display_df.to_string(index=False))\n",
        "    \n",
        "    # Анализ\n",
        "    working_models = results_df[results_df['MSE'] != np.inf]\n",
        "    \n",
        "    if len(working_models) > 0:\n",
        "        best_mse_idx = working_models['MSE'].idxmin()\n",
        "        best_model = working_models.loc[best_mse_idx, 'Model']\n",
        "        best_mse = working_models.loc[best_mse_idx, 'MSE']\n",
        "        \n",
        "        print(f\"\\n🏆 Лучшая модель: {best_model} (MSE: {format_metric(best_mse)})\")\n",
        "        \n",
        "        our_success = [m for m in working_models['Model'] if 'Our' in m]\n",
        "        sklearn_success = [m for m in working_models['Model'] if 'Sklearn' in m]\n",
        "        \n",
        "        print(f\"✅ Наши рабочие модели: {', '.join(our_success) if our_success else 'НЕТ'}\")\n",
        "        print(f\"✅ Библиотечные модели: {', '.join(sklearn_success)}\")\n",
        "    else:\n",
        "        print(\"\\n❌ Все модели не сработали\")\n",
        "    \n",
        "    return results_df\n",
        "\n",
        "# Запускаем финальные эксперименты\n",
        "final_results = run_final_experiments()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Используется существующий DataFrame 'df'\n",
            "\n",
            "🔹 Обучение FastKNNRegressor...\n",
            "🔹 Предсказание...\n",
            "\n",
            "✅ FastKNNRegressor завершён. MAPE = 35.46%\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_true</th>\n",
              "      <th>y_pred</th>\n",
              "      <th>error_%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3600000.0</td>\n",
              "      <td>4364968.00</td>\n",
              "      <td>21.249111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1500000.0</td>\n",
              "      <td>4983367.00</td>\n",
              "      <td>232.224467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4959503.0</td>\n",
              "      <td>3802997.75</td>\n",
              "      <td>23.318975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5356200.0</td>\n",
              "      <td>5094203.00</td>\n",
              "      <td>4.891472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4000000.0</td>\n",
              "      <td>5576520.50</td>\n",
              "      <td>39.413012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6130000.0</td>\n",
              "      <td>6698663.00</td>\n",
              "      <td>9.276721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2750000.0</td>\n",
              "      <td>4864572.00</td>\n",
              "      <td>76.893527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3190000.0</td>\n",
              "      <td>2777607.75</td>\n",
              "      <td>12.927657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8400517.0</td>\n",
              "      <td>9958958.00</td>\n",
              "      <td>18.551727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4590000.0</td>\n",
              "      <td>4824981.00</td>\n",
              "      <td>5.119412</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      y_true      y_pred     error_%\n",
              "0  3600000.0  4364968.00   21.249111\n",
              "1  1500000.0  4983367.00  232.224467\n",
              "2  4959503.0  3802997.75   23.318975\n",
              "3  5356200.0  5094203.00    4.891472\n",
              "4  4000000.0  5576520.50   39.413012\n",
              "5  6130000.0  6698663.00    9.276721\n",
              "6  2750000.0  4864572.00   76.893527\n",
              "7  3190000.0  2777607.75   12.927657\n",
              "8  8400517.0  9958958.00   18.551727\n",
              "9  4590000.0  4824981.00    5.119412"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ==============================================\n",
        "# 🚀 Эксперимент: Быстрый KNN-регрессор без sklearn\n",
        "# ==============================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numba import njit, prange\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ---------- Быстрая евклидова метрика ----------\n",
        "@njit(parallel=True, fastmath=True)\n",
        "def euclidean_distances(X1, X2):\n",
        "    n1, n2 = X1.shape[0], X2.shape[0]\n",
        "    D = np.empty((n1, n2), dtype=np.float32)\n",
        "    for i in prange(n1):\n",
        "        for j in range(n2):\n",
        "            s = 0.0\n",
        "            for k in range(X1.shape[1]):\n",
        "                diff = X1[i, k] - X2[j, k]\n",
        "                s += diff * diff\n",
        "            D[i, j] = np.sqrt(s)\n",
        "    return D\n",
        "\n",
        "# ---------- Наш ускоренный KNN-регрессор ----------\n",
        "class FastKNNRegressor:\n",
        "    def __init__(self, n_neighbors=3, batch_size=5000):\n",
        "        self.k = n_neighbors\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        if not isinstance(X, np.ndarray):\n",
        "            X = X.to_numpy(dtype=np.float32)\n",
        "        if not isinstance(y, np.ndarray):\n",
        "            y = y.to_numpy(dtype=np.float32)\n",
        "        self.X_train = X.astype(np.float32)\n",
        "        self.y_train = y.astype(np.float32)\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not isinstance(X, np.ndarray):\n",
        "            X = X.to_numpy(dtype=np.float32)\n",
        "        X = X.astype(np.float32)\n",
        "\n",
        "        n_test = X.shape[0]\n",
        "        y_pred = np.zeros(n_test, dtype=np.float32)\n",
        "\n",
        "        for start in range(0, n_test, self.batch_size):\n",
        "            end = min(start + self.batch_size, n_test)\n",
        "            X_batch = X[start:end]\n",
        "\n",
        "            dists = euclidean_distances(X_batch, self.X_train)\n",
        "            idx = np.argpartition(dists, self.k, axis=1)[:, :self.k]\n",
        "            nearest_dists = np.take_along_axis(dists, idx, axis=1)\n",
        "            nearest_vals = self.y_train[idx]\n",
        "\n",
        "            weights = 1.0 / (nearest_dists + 1e-6)\n",
        "            weighted_avg = np.sum(nearest_vals * weights, axis=1) / np.sum(weights, axis=1)\n",
        "            y_pred[start:end] = weighted_avg\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "# ---------- Подготовка данных ----------\n",
        "\n",
        "data = df.copy()\n",
        "print(\"✅ Используется существующий DataFrame 'df'\")\n",
        "\n",
        "data = data[:100000]\n",
        "\n",
        "target = \"price\"\n",
        "features = [c for c in data.columns if c != target]\n",
        "\n",
        "# Убираем выбросы\n",
        "q_low, q_high = data[target].quantile([0.05, 0.95])\n",
        "data = data[(data[target] >= q_low) & (data[target] <= q_high)]\n",
        "\n",
        "# Логарифмируем целевую переменную\n",
        "data[target] = np.log1p(data[target])\n",
        "\n",
        "# Масштабирование признаков\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(data[features])\n",
        "y = data[target].values\n",
        "\n",
        "# Разделение данных\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=28)\n",
        "\n",
        "# ---------- Обучение и предсказание ----------\n",
        "print(\"\\n🔹 Обучение FastKNNRegressor...\")\n",
        "knn = FastKNNRegressor(n_neighbors=3, batch_size=200)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "print(\"🔹 Предсказание...\")\n",
        "y_pred_log = knn.predict(X_test)\n",
        "\n",
        "# Обратное преобразование из логарифма\n",
        "y_pred = np.expm1(y_pred_log)\n",
        "y_true = np.expm1(y_test)\n",
        "\n",
        "# ---------- Оценка ----------\n",
        "mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
        "print(f\"\\n✅ FastKNNRegressor завершён. MAPE = {mape:.2f}%\")\n",
        "\n",
        "# Примеры предсказаний\n",
        "pd.DataFrame({\n",
        "    \"y_true\": y_true[:10],\n",
        "    \"y_pred\": y_pred[:10],\n",
        "    \"error_%\": np.abs(y_true[:10] - y_pred[:10]) / y_true[:10] * 100\n",
        "})\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
